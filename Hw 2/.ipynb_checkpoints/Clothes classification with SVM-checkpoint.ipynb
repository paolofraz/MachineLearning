{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clothes Classification with Support Vector Machines\n",
    "\n",
    "In this notebook we are going to explore the use of Support Vector Machines (SVM) for image classification. We are going to use a new version of the famous MNIST dataset (the original is a dataset of handwritten digits). The version we are going to use is called Fashion MNIST (https://pravarmahajan.github.io/fashion/) and is a dataset of small images of clothes and accessories.\n",
    "\n",
    "\n",
    "\n",
    "The dataset labels are the following:\n",
    "\n",
    "| Label | Description |\n",
    "| --- | --- |\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T13:43:54.223630Z",
     "start_time": "2018-12-16T13:43:48.134043Z"
    }
   },
   "outputs": [],
   "source": [
    "#load the required packages\n",
    "\n",
    "%matplotlib inline  \n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import warnings # ignore FutureWarnings, DeprecationWarning ...\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "import sklearn\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T13:43:54.262801Z",
     "start_time": "2018-12-16T13:43:54.223630Z"
    }
   },
   "outputs": [],
   "source": [
    "# helper function to load Fashion MNIST dataset\n",
    "def load_mnist(path, kind='train'):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "    labels_path = os.path.join(path, '%s-labels-idx1-ubyte.gz' % kind)\n",
    "    images_path = os.path.join(path, '%s-images-idx3-ubyte.gz' % kind)\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,offset=8)\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,offset=16).reshape(len(labels), 784) # 28x28 = 784\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T13:43:54.318803Z",
     "start_time": "2018-12-16T13:43:54.282807Z"
    }
   },
   "outputs": [],
   "source": [
    "#fix your ID (\"numero di matricola\") and the seed for random generator (as usual you can try different seeds)\n",
    "ID = 1205687 #replace with your ID\n",
    "np.random.seed(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T13:43:56.893262Z",
     "start_time": "2018-12-16T13:43:54.338807Z"
    }
   },
   "outputs": [],
   "source": [
    "#load the Fashion MNIST dataset from the 'data' folder and let's normalize the features so that each value is in [0,1] \n",
    "\n",
    "X, y = load_mnist('data', kind='train')\n",
    "# rescale the data\n",
    "X, y = X / 255., y # original pixel values are between 0 and 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now split into training and test. Make sure that each label is present at least 10 times\n",
    "in training. If it is not, then keep adding permutations to the initial data until this \n",
    "happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T13:43:57.957770Z",
     "start_time": "2018-12-16T13:43:56.893262Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels in training dataset:  [0 1 2 3 4 5 6 7 8 9]\n",
      "Frequencies in training dataset:  [58 50 55 51 52 37 54 46 51 46]\n"
     ]
    }
   ],
   "source": [
    "#random permute the data and split into training and test taking the first 500\n",
    "#data samples as training and the rests as test\n",
    "permutation = np.random.permutation(X.shape[0])\n",
    "\n",
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "\n",
    "m_training = 500\n",
    "\n",
    "X_train, X_test = X[:m_training], X[m_training:]\n",
    "y_train, y_test = y[:m_training], y[m_training:]\n",
    "\n",
    "labels, freqs = np.unique(y_train, return_counts=True)\n",
    "print(\"Labels in training dataset: \", labels)\n",
    "print(\"Frequencies in training dataset: \", freqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T13:43:57.990955Z",
     "start_time": "2018-12-16T13:43:57.970955Z"
    }
   },
   "outputs": [],
   "source": [
    "#function for plotting a image and printing the corresponding label\n",
    "def plot_input(X_matrix, labels, index):\n",
    "    print(\"INPUT:\")\n",
    "    plt.imshow(\n",
    "        X_matrix[index].reshape(28,28),\n",
    "        cmap          = plt.cm.gray_r,\n",
    "        interpolation = \"nearest\"\n",
    "    )\n",
    "    plt.show()\n",
    "    print(\"LABEL: %i\"%labels[index])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T13:44:00.095204Z",
     "start_time": "2018-12-16T13:43:57.998954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 1\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 5\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 1\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 6\n"
     ]
    }
   ],
   "source": [
    "#let's try the plotting function\n",
    "plot_input(X_train,y_train,10)\n",
    "plot_input(X_test,y_test,100)\n",
    "plot_input(X_test,y_test,1000)\n",
    "plot_input(X_test,y_test,10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 1\n",
    "Use a SVM classifier with cross validation to pick a model. Use a 5-fold cross-validation. Let's start with a Linear kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T13:44:21.904775Z",
     "start_time": "2018-12-16T13:44:00.103207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   20.6s finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR LINEAR KERNEL \n",
      "\n",
      "Best parameters set found: {'C': 0.1}\n",
      "Score with best parameters: 0.794\n"
     ]
    }
   ],
   "source": [
    "#import SVC\n",
    "from sklearn.svm import SVC\n",
    "#import for Cross-Validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#grid of parameters for your SVC\n",
    "#param_grid = [\n",
    "#  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "#  {'C': [1, 10, 100, 1000], 'gamma': [0.01, 0.001], 'kernel': ['rbf']},\n",
    "#  {'C': [1, 10, 100, 1000], 'gamma': [0.01, 0.001], 'kernel': ['poly']},\n",
    "# ]\n",
    "\n",
    "# parameters for linear SVM\n",
    "parameters = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "#run linear SVM\n",
    "\n",
    "### ADD CODE: FIT MODEL USING 5-fold CV\n",
    "lin_svm = SVC(kernel='linear',decision_function_shape='ovo')\n",
    "grid_search_lin = GridSearchCV(lin_svm, parameters, cv=5,verbose=2, n_jobs=-1) # verbose output and use all processors\n",
    "grid_search_lin.fit(X_train,y_train)\n",
    "\n",
    "print ('RESULTS FOR LINEAR KERNEL \\n')\n",
    "\n",
    "lin_best_params = grid_search_lin.best_params_\n",
    "print(\"Best parameters set found:\", lin_best_params)\n",
    "### ADD CODE\n",
    "\n",
    "lin_best_score = grid_search_lin.best_score_\n",
    "print(\"Score with best parameters:\", lin_best_score)\n",
    "### ADD CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T13:44:22.304776Z",
     "start_time": "2018-12-16T13:44:21.924772Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All scores on the grid:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.067203</td>\n",
       "      <td>0.023103</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.019032</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.001}</td>\n",
       "      <td>0.590476</td>\n",
       "      <td>0.574257</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>0.551020</td>\n",
       "      <td>0.670103</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.050984</td>\n",
       "      <td>6</td>\n",
       "      <td>0.648101</td>\n",
       "      <td>0.694236</td>\n",
       "      <td>0.660848</td>\n",
       "      <td>0.656716</td>\n",
       "      <td>0.655087</td>\n",
       "      <td>0.662998</td>\n",
       "      <td>0.016152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.556003</td>\n",
       "      <td>0.025548</td>\n",
       "      <td>0.123400</td>\n",
       "      <td>0.012450</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.752381</td>\n",
       "      <td>0.722772</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.886598</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.055966</td>\n",
       "      <td>5</td>\n",
       "      <td>0.850633</td>\n",
       "      <td>0.869674</td>\n",
       "      <td>0.850374</td>\n",
       "      <td>0.848259</td>\n",
       "      <td>0.828784</td>\n",
       "      <td>0.849545</td>\n",
       "      <td>0.012959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.442035</td>\n",
       "      <td>0.022236</td>\n",
       "      <td>0.116739</td>\n",
       "      <td>0.012285</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>0.712871</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.855670</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.046760</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>0.987469</td>\n",
       "      <td>0.980050</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.977667</td>\n",
       "      <td>0.983520</td>\n",
       "      <td>0.003973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.598872</td>\n",
       "      <td>0.182893</td>\n",
       "      <td>0.193474</td>\n",
       "      <td>0.071805</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.780952</td>\n",
       "      <td>0.742574</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.030555</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.715997</td>\n",
       "      <td>0.169762</td>\n",
       "      <td>0.134403</td>\n",
       "      <td>0.035481</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>0.780952</td>\n",
       "      <td>0.742574</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.030555</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.632805</td>\n",
       "      <td>0.104351</td>\n",
       "      <td>0.172796</td>\n",
       "      <td>0.053807</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 100}</td>\n",
       "      <td>0.780952</td>\n",
       "      <td>0.742574</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.030555</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       1.067203      0.023103         0.166400        0.019032   0.001   \n",
       "1       0.556003      0.025548         0.123400        0.012450    0.01   \n",
       "2       0.442035      0.022236         0.116739        0.012285     0.1   \n",
       "3       0.598872      0.182893         0.193474        0.071805       1   \n",
       "4       0.715997      0.169762         0.134403        0.035481      10   \n",
       "5       0.632805      0.104351         0.172796        0.053807     100   \n",
       "\n",
       "         params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0  {'C': 0.001}           0.590476           0.574257           0.676768   \n",
       "1   {'C': 0.01}           0.752381           0.722772           0.757576   \n",
       "2    {'C': 0.1}           0.790476           0.712871           0.818182   \n",
       "3      {'C': 1}           0.780952           0.742574           0.808081   \n",
       "4     {'C': 10}           0.780952           0.742574           0.808081   \n",
       "5    {'C': 100}           0.780952           0.742574           0.808081   \n",
       "\n",
       "   split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.551020           0.670103            0.612        0.050984   \n",
       "1           0.785714           0.886598            0.780        0.055966   \n",
       "2           0.795918           0.855670            0.794        0.046760   \n",
       "3           0.785714           0.835052            0.790        0.030555   \n",
       "4           0.785714           0.835052            0.790        0.030555   \n",
       "5           0.785714           0.835052            0.790        0.030555   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                6            0.648101            0.694236   \n",
       "1                5            0.850633            0.869674   \n",
       "2                1            0.987342            0.987469   \n",
       "3                2            1.000000            1.000000   \n",
       "4                2            1.000000            1.000000   \n",
       "5                2            1.000000            1.000000   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.660848            0.656716            0.655087   \n",
       "1            0.850374            0.848259            0.828784   \n",
       "2            0.980050            0.985075            0.977667   \n",
       "3            1.000000            1.000000            1.000000   \n",
       "4            1.000000            1.000000            1.000000   \n",
       "5            1.000000            1.000000            1.000000   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.662998         0.016152  \n",
       "1          0.849545         0.012959  \n",
       "2          0.983520         0.003973  \n",
       "3          1.000000         0.000000  \n",
       "4          1.000000         0.000000  \n",
       "5          1.000000         0.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"All scores on the grid:\")\n",
    "pd.set_option('display.max_columns', 50) # display all columns\n",
    "pd.set_option('display.max_rows', 50) # display all rows\n",
    "pd.DataFrame(grid_search_lin.cv_results_)### ADD CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T21:46:32.098333Z",
     "start_time": "2018-12-06T21:46:32.082378Z"
    },
    "collapsed": true
   },
   "source": [
    "## TO DO 2\n",
    "Pick a model for the Polynomial kernel with degree=2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T13:44:41.892774Z",
     "start_time": "2018-12-16T13:44:22.324767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   18.9s finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR POLY DEGREE=2 KERNEL\n",
      "Best parameters set found: {'C': 0.01, 'gamma': 1.0}\n",
      "Score with best parameters: 0.794\n"
     ]
    }
   ],
   "source": [
    "# parameters for poly with degree 2 kernel\n",
    "parameters = {'C': [0.01, 0.1, 1],'gamma':[0.01,0.1,1.]}\n",
    "\n",
    "#run SVM with poly of degree 2 kernel\n",
    "\n",
    "# ADD CODE\n",
    "poly_svm = SVC(kernel='poly',degree=2,decision_function_shape='ovo')\n",
    "grid_search_poly = GridSearchCV(poly_svm, parameters, cv=5, verbose=2, n_jobs=-1) # verbose output and using all processors\n",
    "grid_search_poly.fit(X_train,y_train)\n",
    "\n",
    "print ('RESULTS FOR POLY DEGREE=2 KERNEL')\n",
    "\n",
    "poly_best_params = grid_search_poly.best_params_\n",
    "print(\"Best parameters set found:\", poly_best_params)\n",
    "### ADD CODE\n",
    "\n",
    "poly_score = grid_search_poly.best_score_\n",
    "print(\"Score with best parameters:\",poly_score)\n",
    "### ADD CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T13:44:42.104776Z",
     "start_time": "2018-12-16T13:44:41.900777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All scores on the grid:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.601601</td>\n",
       "      <td>0.084724</td>\n",
       "      <td>0.337602</td>\n",
       "      <td>0.025874</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.01}</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.118812</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.112245</td>\n",
       "      <td>0.113402</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.003416</td>\n",
       "      <td>9</td>\n",
       "      <td>0.116456</td>\n",
       "      <td>0.117794</td>\n",
       "      <td>0.114713</td>\n",
       "      <td>0.116915</td>\n",
       "      <td>0.116625</td>\n",
       "      <td>0.116501</td>\n",
       "      <td>0.001006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.204800</td>\n",
       "      <td>0.085731</td>\n",
       "      <td>0.303203</td>\n",
       "      <td>0.051501</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.1}</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.744898</td>\n",
       "      <td>0.845361</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.058773</td>\n",
       "      <td>6</td>\n",
       "      <td>0.873418</td>\n",
       "      <td>0.892231</td>\n",
       "      <td>0.877805</td>\n",
       "      <td>0.878109</td>\n",
       "      <td>0.880893</td>\n",
       "      <td>0.880491</td>\n",
       "      <td>0.006339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.598402</td>\n",
       "      <td>0.210880</td>\n",
       "      <td>0.125599</td>\n",
       "      <td>0.035474</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.01, 'gamma': 1.0}</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>0.712871</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.824742</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.042964</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.915198</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.147201</td>\n",
       "      <td>0.004665</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.01}</td>\n",
       "      <td>0.638095</td>\n",
       "      <td>0.564356</td>\n",
       "      <td>0.707071</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.731959</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.067863</td>\n",
       "      <td>8</td>\n",
       "      <td>0.670886</td>\n",
       "      <td>0.704261</td>\n",
       "      <td>0.663342</td>\n",
       "      <td>0.708955</td>\n",
       "      <td>0.667494</td>\n",
       "      <td>0.682987</td>\n",
       "      <td>0.019490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.463999</td>\n",
       "      <td>0.022626</td>\n",
       "      <td>0.104800</td>\n",
       "      <td>0.004664</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.1}</td>\n",
       "      <td>0.780952</td>\n",
       "      <td>0.722772</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.042273</td>\n",
       "      <td>5</td>\n",
       "      <td>0.992405</td>\n",
       "      <td>0.989975</td>\n",
       "      <td>0.992519</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>0.995037</td>\n",
       "      <td>0.993490</td>\n",
       "      <td>0.002571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.464001</td>\n",
       "      <td>0.011865</td>\n",
       "      <td>0.099198</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.1, 'gamma': 1.0}</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>0.712871</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.824742</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.042964</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.550402</td>\n",
       "      <td>0.026484</td>\n",
       "      <td>0.127199</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.744898</td>\n",
       "      <td>0.845361</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.058773</td>\n",
       "      <td>6</td>\n",
       "      <td>0.873418</td>\n",
       "      <td>0.892231</td>\n",
       "      <td>0.877805</td>\n",
       "      <td>0.878109</td>\n",
       "      <td>0.880893</td>\n",
       "      <td>0.880491</td>\n",
       "      <td>0.006339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.496801</td>\n",
       "      <td>0.031437</td>\n",
       "      <td>0.127999</td>\n",
       "      <td>0.019595</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1}</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>0.712871</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.824742</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.042964</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.477601</td>\n",
       "      <td>0.038252</td>\n",
       "      <td>0.105600</td>\n",
       "      <td>0.005426</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1, 'gamma': 1.0}</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>0.712871</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.824742</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.042964</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       2.601601      0.084724         0.337602        0.025874    0.01   \n",
       "1       1.204800      0.085731         0.303203        0.051501    0.01   \n",
       "2       0.598402      0.210880         0.125599        0.035474    0.01   \n",
       "3       0.915198      0.017600         0.147201        0.004665     0.1   \n",
       "4       0.463999      0.022626         0.104800        0.004664     0.1   \n",
       "5       0.464001      0.011865         0.099198        0.002993     0.1   \n",
       "6       0.550402      0.026484         0.127199        0.009599       1   \n",
       "7       0.496801      0.031437         0.127999        0.019595       1   \n",
       "8       0.477601      0.038252         0.105600        0.005426       1   \n",
       "\n",
       "  param_gamma                      params  split0_test_score  \\\n",
       "0        0.01  {'C': 0.01, 'gamma': 0.01}           0.114286   \n",
       "1         0.1   {'C': 0.01, 'gamma': 0.1}           0.733333   \n",
       "2           1   {'C': 0.01, 'gamma': 1.0}           0.790476   \n",
       "3        0.01   {'C': 0.1, 'gamma': 0.01}           0.638095   \n",
       "4         0.1    {'C': 0.1, 'gamma': 0.1}           0.780952   \n",
       "5           1    {'C': 0.1, 'gamma': 1.0}           0.790476   \n",
       "6        0.01     {'C': 1, 'gamma': 0.01}           0.733333   \n",
       "7         0.1      {'C': 1, 'gamma': 0.1}           0.790476   \n",
       "8           1      {'C': 1, 'gamma': 1.0}           0.790476   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.118812           0.121212           0.112245           0.113402   \n",
       "1           0.683168           0.818182           0.744898           0.845361   \n",
       "2           0.712871           0.828283           0.816327           0.824742   \n",
       "3           0.564356           0.707071           0.571429           0.731959   \n",
       "4           0.722772           0.838384           0.785714           0.835052   \n",
       "5           0.712871           0.828283           0.816327           0.824742   \n",
       "6           0.683168           0.818182           0.744898           0.845361   \n",
       "7           0.712871           0.828283           0.816327           0.824742   \n",
       "8           0.712871           0.828283           0.816327           0.824742   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0            0.116        0.003416                9            0.116456   \n",
       "1            0.764        0.058773                6            0.873418   \n",
       "2            0.794        0.042964                1            1.000000   \n",
       "3            0.642        0.067863                8            0.670886   \n",
       "4            0.792        0.042273                5            0.992405   \n",
       "5            0.794        0.042964                1            1.000000   \n",
       "6            0.764        0.058773                6            0.873418   \n",
       "7            0.794        0.042964                1            1.000000   \n",
       "8            0.794        0.042964                1            1.000000   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.117794            0.114713            0.116915   \n",
       "1            0.892231            0.877805            0.878109   \n",
       "2            1.000000            1.000000            1.000000   \n",
       "3            0.704261            0.663342            0.708955   \n",
       "4            0.989975            0.992519            0.997512   \n",
       "5            1.000000            1.000000            1.000000   \n",
       "6            0.892231            0.877805            0.878109   \n",
       "7            1.000000            1.000000            1.000000   \n",
       "8            1.000000            1.000000            1.000000   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.116625          0.116501         0.001006  \n",
       "1            0.880893          0.880491         0.006339  \n",
       "2            1.000000          1.000000         0.000000  \n",
       "3            0.667494          0.682987         0.019490  \n",
       "4            0.995037          0.993490         0.002571  \n",
       "5            1.000000          1.000000         0.000000  \n",
       "6            0.880893          0.880491         0.006339  \n",
       "7            1.000000          1.000000         0.000000  \n",
       "8            1.000000          1.000000         0.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nAll scores on the grid:\")\n",
    "pd.DataFrame(grid_search_poly.cv_results_)### ADD CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 3\n",
    "\n",
    "Now let's try a higher degree for the polynomial kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T13:44:57.048783Z",
     "start_time": "2018-12-16T13:44:42.116779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   14.2s finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR POLY DEGREE = 3  KERNEL\n",
      "Best parameters set found: {'C': 0.01, 'gamma': 1.0}\n",
      "Score with best parameters: 0.772\n"
     ]
    }
   ],
   "source": [
    "# parameters for poly with higher degree kernel\n",
    "parameters = {'C': [0.01, 0.1, 1],'gamma':[0.01,0.1,1.]}\n",
    "\n",
    "#run SVM with poly of higher degree kernel\n",
    "degree = 3\n",
    "\n",
    "### ADD CODE\n",
    "poly3_svm = SVC(kernel='poly',degree=degree,decision_function_shape='ovo')\n",
    "grid_search_poly3 = GridSearchCV(poly3_svm, parameters, cv=5, verbose=2, n_jobs=-1) # verbose output and using all processors\n",
    "grid_search_poly3.fit(X_train,y_train)\n",
    "\n",
    "print ('RESULTS FOR POLY DEGREE =', degree, ' KERNEL')\n",
    "\n",
    "poly3_best_params = grid_search_poly3.best_params_\n",
    "print(\"Best parameters set found:\", poly3_best_params)\n",
    "### ADD CODE\n",
    "\n",
    "poly3_score = grid_search_poly3.best_score_\n",
    "print(\"Score with best parameters:\", poly3_score)\n",
    "### ADD CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T13:44:57.260783Z",
     "start_time": "2018-12-16T13:44:57.060786Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All scores on the grid:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.345602</td>\n",
       "      <td>0.076589</td>\n",
       "      <td>0.204799</td>\n",
       "      <td>0.013947</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.01}</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.316832</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.438776</td>\n",
       "      <td>0.422680</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.059411</td>\n",
       "      <td>9</td>\n",
       "      <td>0.415190</td>\n",
       "      <td>0.453634</td>\n",
       "      <td>0.408978</td>\n",
       "      <td>0.462687</td>\n",
       "      <td>0.436725</td>\n",
       "      <td>0.435443</td>\n",
       "      <td>0.020906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.456001</td>\n",
       "      <td>0.011027</td>\n",
       "      <td>0.103200</td>\n",
       "      <td>0.012998</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.1}</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.693069</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.744898</td>\n",
       "      <td>0.793814</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.045600</td>\n",
       "      <td>6</td>\n",
       "      <td>0.959494</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.962594</td>\n",
       "      <td>0.957711</td>\n",
       "      <td>0.962779</td>\n",
       "      <td>0.961498</td>\n",
       "      <td>0.002563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.517599</td>\n",
       "      <td>0.058877</td>\n",
       "      <td>0.119200</td>\n",
       "      <td>0.024053</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.01, 'gamma': 1.0}</td>\n",
       "      <td>0.780952</td>\n",
       "      <td>0.712871</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.765306</td>\n",
       "      <td>0.804124</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.032645</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.909601</td>\n",
       "      <td>0.059631</td>\n",
       "      <td>0.151201</td>\n",
       "      <td>0.014622</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.01}</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.544554</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>0.540816</td>\n",
       "      <td>0.701031</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.065404</td>\n",
       "      <td>8</td>\n",
       "      <td>0.660759</td>\n",
       "      <td>0.709273</td>\n",
       "      <td>0.678304</td>\n",
       "      <td>0.728856</td>\n",
       "      <td>0.682382</td>\n",
       "      <td>0.691915</td>\n",
       "      <td>0.024136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.411999</td>\n",
       "      <td>0.012394</td>\n",
       "      <td>0.100802</td>\n",
       "      <td>0.007755</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.1}</td>\n",
       "      <td>0.780952</td>\n",
       "      <td>0.712871</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.765306</td>\n",
       "      <td>0.804124</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.032645</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998996</td>\n",
       "      <td>0.001230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.408001</td>\n",
       "      <td>0.017526</td>\n",
       "      <td>0.091200</td>\n",
       "      <td>0.005880</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.1, 'gamma': 1.0}</td>\n",
       "      <td>0.780952</td>\n",
       "      <td>0.712871</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.765306</td>\n",
       "      <td>0.804124</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.032645</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.589600</td>\n",
       "      <td>0.048172</td>\n",
       "      <td>0.155200</td>\n",
       "      <td>0.040270</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>0.704762</td>\n",
       "      <td>0.673267</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.773196</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.041555</td>\n",
       "      <td>7</td>\n",
       "      <td>0.860759</td>\n",
       "      <td>0.889724</td>\n",
       "      <td>0.855362</td>\n",
       "      <td>0.885572</td>\n",
       "      <td>0.878412</td>\n",
       "      <td>0.873966</td>\n",
       "      <td>0.013589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.472800</td>\n",
       "      <td>0.060895</td>\n",
       "      <td>0.123999</td>\n",
       "      <td>0.024657</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1}</td>\n",
       "      <td>0.780952</td>\n",
       "      <td>0.712871</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.765306</td>\n",
       "      <td>0.804124</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.032645</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.431999</td>\n",
       "      <td>0.029394</td>\n",
       "      <td>0.119202</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1, 'gamma': 1.0}</td>\n",
       "      <td>0.780952</td>\n",
       "      <td>0.712871</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.765306</td>\n",
       "      <td>0.804124</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.032645</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       1.345602      0.076589         0.204799        0.013947    0.01   \n",
       "1       0.456001      0.011027         0.103200        0.012998    0.01   \n",
       "2       0.517599      0.058877         0.119200        0.024053    0.01   \n",
       "3       0.909601      0.059631         0.151201        0.014622     0.1   \n",
       "4       0.411999      0.012394         0.100802        0.007755     0.1   \n",
       "5       0.408001      0.017526         0.091200        0.005880     0.1   \n",
       "6       0.589600      0.048172         0.155200        0.040270       1   \n",
       "7       0.472800      0.060895         0.123999        0.024657       1   \n",
       "8       0.431999      0.029394         0.119202        0.024580       1   \n",
       "\n",
       "  param_gamma                      params  split0_test_score  \\\n",
       "0        0.01  {'C': 0.01, 'gamma': 0.01}           0.314286   \n",
       "1         0.1   {'C': 0.01, 'gamma': 0.1}           0.761905   \n",
       "2           1   {'C': 0.01, 'gamma': 1.0}           0.780952   \n",
       "3        0.01   {'C': 0.1, 'gamma': 0.01}           0.609524   \n",
       "4         0.1    {'C': 0.1, 'gamma': 0.1}           0.780952   \n",
       "5           1    {'C': 0.1, 'gamma': 1.0}           0.780952   \n",
       "6        0.01     {'C': 1, 'gamma': 0.01}           0.704762   \n",
       "7         0.1      {'C': 1, 'gamma': 0.1}           0.780952   \n",
       "8           1      {'C': 1, 'gamma': 1.0}           0.780952   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.316832           0.444444           0.438776           0.422680   \n",
       "1           0.693069           0.828283           0.744898           0.793814   \n",
       "2           0.712871           0.797980           0.765306           0.804124   \n",
       "3           0.544554           0.676768           0.540816           0.701031   \n",
       "4           0.712871           0.797980           0.765306           0.804124   \n",
       "5           0.712871           0.797980           0.765306           0.804124   \n",
       "6           0.673267           0.757576           0.673469           0.773196   \n",
       "7           0.712871           0.797980           0.765306           0.804124   \n",
       "8           0.712871           0.797980           0.765306           0.804124   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0            0.386        0.059411                9            0.415190   \n",
       "1            0.764        0.045600                6            0.959494   \n",
       "2            0.772        0.032645                1            1.000000   \n",
       "3            0.614        0.065404                8            0.660759   \n",
       "4            0.772        0.032645                1            0.997468   \n",
       "5            0.772        0.032645                1            1.000000   \n",
       "6            0.716        0.041555                7            0.860759   \n",
       "7            0.772        0.032645                1            1.000000   \n",
       "8            0.772        0.032645                1            1.000000   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.453634            0.408978            0.462687   \n",
       "1            0.964912            0.962594            0.957711   \n",
       "2            1.000000            1.000000            1.000000   \n",
       "3            0.709273            0.678304            0.728856   \n",
       "4            1.000000            1.000000            0.997512   \n",
       "5            1.000000            1.000000            1.000000   \n",
       "6            0.889724            0.855362            0.885572   \n",
       "7            1.000000            1.000000            1.000000   \n",
       "8            1.000000            1.000000            1.000000   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.436725          0.435443         0.020906  \n",
       "1            0.962779          0.961498         0.002563  \n",
       "2            1.000000          1.000000         0.000000  \n",
       "3            0.682382          0.691915         0.024136  \n",
       "4            1.000000          0.998996         0.001230  \n",
       "5            1.000000          1.000000         0.000000  \n",
       "6            0.878412          0.873966         0.013589  \n",
       "7            1.000000          1.000000         0.000000  \n",
       "8            1.000000          1.000000         0.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nAll scores on the grid:\")\n",
    "pd.DataFrame(grid_search_poly3.cv_results_)### ADD CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO4 \n",
    "What do you observe when fitting a higher degree polynomial on this dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** A higher degree polynomial fit results to lower scores than the linear kernel, meaning that polynomial kernels are not the best suited for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 5\n",
    "Pick a model for the Radial Basis Function kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T13:45:42.414059Z",
     "start_time": "2018-12-16T13:44:57.268787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   44.1s finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR rbf KERNEL\n",
      "Best parameters set found: {'C': 10, 'gamma': 0.01}\n",
      "Score with best parameters: 0.82\n"
     ]
    }
   ],
   "source": [
    "# parameters for rbf SVM\n",
    "parameters = {'C': [0.1, 1, 10, 100],'gamma':[0.001, 0.01, 0.01,0.1]}\n",
    "\n",
    "#run SVM with rbf kernel\n",
    "\n",
    "### ADD CODE\n",
    "rbf_svm = SVC(kernel='rbf',decision_function_shape='ovo')\n",
    "grid_search_rbf = GridSearchCV(rbf_svm, parameters, cv=5, verbose=2, n_jobs=-1) # verbose output and using all processors\n",
    "grid_search_rbf.fit(X_train,y_train)\n",
    "\n",
    "print ('RESULTS FOR rbf KERNEL')\n",
    "\n",
    "rbf_best_params = grid_search_rbf.best_params_\n",
    "print(\"Best parameters set found:\", rbf_best_params)\n",
    "### ADD CODE\n",
    "\n",
    "rbf_score = grid_search_rbf.best_score_\n",
    "print(\"Score with best parameters:\",rbf_score)\n",
    "### ADD CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T13:45:42.578022Z",
     "start_time": "2018-12-16T13:45:42.418021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All scores on the grid:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.587201</td>\n",
       "      <td>0.073380</td>\n",
       "      <td>0.166399</td>\n",
       "      <td>0.010308</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.001}</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.118812</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.112245</td>\n",
       "      <td>0.113402</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.003416</td>\n",
       "      <td>15</td>\n",
       "      <td>0.116456</td>\n",
       "      <td>0.115288</td>\n",
       "      <td>0.114713</td>\n",
       "      <td>0.116915</td>\n",
       "      <td>0.116625</td>\n",
       "      <td>0.116000</td>\n",
       "      <td>0.000848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.484000</td>\n",
       "      <td>0.205181</td>\n",
       "      <td>0.168799</td>\n",
       "      <td>0.008158</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.01}</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.524752</td>\n",
       "      <td>0.686869</td>\n",
       "      <td>0.581633</td>\n",
       "      <td>0.608247</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.053410</td>\n",
       "      <td>13</td>\n",
       "      <td>0.622785</td>\n",
       "      <td>0.659148</td>\n",
       "      <td>0.610973</td>\n",
       "      <td>0.631841</td>\n",
       "      <td>0.610422</td>\n",
       "      <td>0.627034</td>\n",
       "      <td>0.017924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.592804</td>\n",
       "      <td>0.066139</td>\n",
       "      <td>0.186397</td>\n",
       "      <td>0.018526</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.01}</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.524752</td>\n",
       "      <td>0.686869</td>\n",
       "      <td>0.581633</td>\n",
       "      <td>0.608247</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.053410</td>\n",
       "      <td>13</td>\n",
       "      <td>0.622785</td>\n",
       "      <td>0.659148</td>\n",
       "      <td>0.610973</td>\n",
       "      <td>0.631841</td>\n",
       "      <td>0.610422</td>\n",
       "      <td>0.627034</td>\n",
       "      <td>0.017924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.460800</td>\n",
       "      <td>0.053389</td>\n",
       "      <td>0.169598</td>\n",
       "      <td>0.006972</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.1}</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.118812</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.112245</td>\n",
       "      <td>0.113402</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.003416</td>\n",
       "      <td>15</td>\n",
       "      <td>0.116456</td>\n",
       "      <td>0.115288</td>\n",
       "      <td>0.114713</td>\n",
       "      <td>0.116915</td>\n",
       "      <td>0.116625</td>\n",
       "      <td>0.116000</td>\n",
       "      <td>0.000848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.991201</td>\n",
       "      <td>0.041368</td>\n",
       "      <td>0.195198</td>\n",
       "      <td>0.045283</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.001}</td>\n",
       "      <td>0.695238</td>\n",
       "      <td>0.693069</td>\n",
       "      <td>0.717172</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.783505</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.032644</td>\n",
       "      <td>9</td>\n",
       "      <td>0.756962</td>\n",
       "      <td>0.759398</td>\n",
       "      <td>0.773067</td>\n",
       "      <td>0.763682</td>\n",
       "      <td>0.751861</td>\n",
       "      <td>0.760994</td>\n",
       "      <td>0.007144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.821601</td>\n",
       "      <td>0.080581</td>\n",
       "      <td>0.156799</td>\n",
       "      <td>0.023919</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>0.780952</td>\n",
       "      <td>0.732673</td>\n",
       "      <td>0.767677</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.845361</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.036269</td>\n",
       "      <td>6</td>\n",
       "      <td>0.888608</td>\n",
       "      <td>0.917293</td>\n",
       "      <td>0.885287</td>\n",
       "      <td>0.898010</td>\n",
       "      <td>0.875931</td>\n",
       "      <td>0.893026</td>\n",
       "      <td>0.014039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.849600</td>\n",
       "      <td>0.033523</td>\n",
       "      <td>0.161601</td>\n",
       "      <td>0.020016</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>0.780952</td>\n",
       "      <td>0.732673</td>\n",
       "      <td>0.767677</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.845361</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.036269</td>\n",
       "      <td>6</td>\n",
       "      <td>0.888608</td>\n",
       "      <td>0.917293</td>\n",
       "      <td>0.885287</td>\n",
       "      <td>0.898010</td>\n",
       "      <td>0.875931</td>\n",
       "      <td>0.893026</td>\n",
       "      <td>0.014039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.580243</td>\n",
       "      <td>0.104735</td>\n",
       "      <td>0.200801</td>\n",
       "      <td>0.036958</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.495050</td>\n",
       "      <td>0.595960</td>\n",
       "      <td>0.622449</td>\n",
       "      <td>0.711340</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.073084</td>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.584002</td>\n",
       "      <td>0.020239</td>\n",
       "      <td>0.128799</td>\n",
       "      <td>0.007755</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001}</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.693069</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.865979</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.055016</td>\n",
       "      <td>6</td>\n",
       "      <td>0.893671</td>\n",
       "      <td>0.914787</td>\n",
       "      <td>0.902743</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.885856</td>\n",
       "      <td>0.901501</td>\n",
       "      <td>0.010622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.771201</td>\n",
       "      <td>0.034073</td>\n",
       "      <td>0.139206</td>\n",
       "      <td>0.011703</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01}</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>0.732673</td>\n",
       "      <td>0.858586</td>\n",
       "      <td>0.826531</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.056339</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.723198</td>\n",
       "      <td>0.010852</td>\n",
       "      <td>0.136004</td>\n",
       "      <td>0.005062</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01}</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>0.732673</td>\n",
       "      <td>0.858586</td>\n",
       "      <td>0.826531</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.056339</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.696802</td>\n",
       "      <td>0.129847</td>\n",
       "      <td>0.243999</td>\n",
       "      <td>0.062636</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 10, 'gamma': 0.1}</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.514851</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.663265</td>\n",
       "      <td>0.721649</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.069202</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.714398</td>\n",
       "      <td>0.066818</td>\n",
       "      <td>0.167999</td>\n",
       "      <td>0.062482</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.001}</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.722772</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.806122</td>\n",
       "      <td>0.865979</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.046884</td>\n",
       "      <td>5</td>\n",
       "      <td>0.997468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997519</td>\n",
       "      <td>0.998997</td>\n",
       "      <td>0.001228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.101601</td>\n",
       "      <td>0.074559</td>\n",
       "      <td>0.210398</td>\n",
       "      <td>0.043125</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01}</td>\n",
       "      <td>0.780952</td>\n",
       "      <td>0.732673</td>\n",
       "      <td>0.858586</td>\n",
       "      <td>0.826531</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.057509</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.263199</td>\n",
       "      <td>0.194259</td>\n",
       "      <td>0.203200</td>\n",
       "      <td>0.056932</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01}</td>\n",
       "      <td>0.780952</td>\n",
       "      <td>0.732673</td>\n",
       "      <td>0.858586</td>\n",
       "      <td>0.826531</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.057509</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.940802</td>\n",
       "      <td>0.254870</td>\n",
       "      <td>0.215998</td>\n",
       "      <td>0.037352</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 100, 'gamma': 0.1}</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.514851</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.663265</td>\n",
       "      <td>0.721649</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.069202</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        1.587201      0.073380         0.166399        0.010308     0.1   \n",
       "1        1.484000      0.205181         0.168799        0.008158     0.1   \n",
       "2        1.592804      0.066139         0.186397        0.018526     0.1   \n",
       "3        1.460800      0.053389         0.169598        0.006972     0.1   \n",
       "4        0.991201      0.041368         0.195198        0.045283       1   \n",
       "5        0.821601      0.080581         0.156799        0.023919       1   \n",
       "6        0.849600      0.033523         0.161601        0.020016       1   \n",
       "7        1.580243      0.104735         0.200801        0.036958       1   \n",
       "8        0.584002      0.020239         0.128799        0.007755      10   \n",
       "9        0.771201      0.034073         0.139206        0.011703      10   \n",
       "10       0.723198      0.010852         0.136004        0.005062      10   \n",
       "11       1.696802      0.129847         0.243999        0.062636      10   \n",
       "12       0.714398      0.066818         0.167999        0.062482     100   \n",
       "13       1.101601      0.074559         0.210398        0.043125     100   \n",
       "14       1.263199      0.194259         0.203200        0.056932     100   \n",
       "15       1.940802      0.254870         0.215998        0.037352     100   \n",
       "\n",
       "   param_gamma                      params  split0_test_score  \\\n",
       "0        0.001  {'C': 0.1, 'gamma': 0.001}           0.114286   \n",
       "1         0.01   {'C': 0.1, 'gamma': 0.01}           0.571429   \n",
       "2         0.01   {'C': 0.1, 'gamma': 0.01}           0.571429   \n",
       "3          0.1    {'C': 0.1, 'gamma': 0.1}           0.114286   \n",
       "4        0.001    {'C': 1, 'gamma': 0.001}           0.695238   \n",
       "5         0.01     {'C': 1, 'gamma': 0.01}           0.780952   \n",
       "6         0.01     {'C': 1, 'gamma': 0.01}           0.780952   \n",
       "7          0.1      {'C': 1, 'gamma': 0.1}           0.666667   \n",
       "8        0.001   {'C': 10, 'gamma': 0.001}           0.771429   \n",
       "9         0.01    {'C': 10, 'gamma': 0.01}           0.790476   \n",
       "10        0.01    {'C': 10, 'gamma': 0.01}           0.790476   \n",
       "11         0.1     {'C': 10, 'gamma': 0.1}           0.657143   \n",
       "12       0.001  {'C': 100, 'gamma': 0.001}           0.809524   \n",
       "13        0.01   {'C': 100, 'gamma': 0.01}           0.780952   \n",
       "14        0.01   {'C': 100, 'gamma': 0.01}           0.780952   \n",
       "15         0.1    {'C': 100, 'gamma': 0.1}           0.657143   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.118812           0.121212           0.112245   \n",
       "1            0.524752           0.686869           0.581633   \n",
       "2            0.524752           0.686869           0.581633   \n",
       "3            0.118812           0.121212           0.112245   \n",
       "4            0.693069           0.717172           0.714286   \n",
       "5            0.732673           0.767677           0.775510   \n",
       "6            0.732673           0.767677           0.775510   \n",
       "7            0.495050           0.595960           0.622449   \n",
       "8            0.693069           0.777778           0.795918   \n",
       "9            0.732673           0.858586           0.826531   \n",
       "10           0.732673           0.858586           0.826531   \n",
       "11           0.514851           0.606061           0.663265   \n",
       "12           0.722772           0.828283           0.806122   \n",
       "13           0.732673           0.858586           0.826531   \n",
       "14           0.732673           0.858586           0.826531   \n",
       "15           0.514851           0.606061           0.663265   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0            0.113402            0.116        0.003416               15   \n",
       "1            0.608247            0.594        0.053410               13   \n",
       "2            0.608247            0.594        0.053410               13   \n",
       "3            0.113402            0.116        0.003416               15   \n",
       "4            0.783505            0.720        0.032644                9   \n",
       "5            0.845361            0.780        0.036269                6   \n",
       "6            0.845361            0.780        0.036269                6   \n",
       "7            0.711340            0.618        0.073084               12   \n",
       "8            0.865979            0.780        0.055016                6   \n",
       "9            0.896907            0.820        0.056339                1   \n",
       "10           0.896907            0.820        0.056339                1   \n",
       "11           0.721649            0.632        0.069202               10   \n",
       "12           0.865979            0.806        0.046884                5   \n",
       "13           0.896907            0.818        0.057509                3   \n",
       "14           0.896907            0.818        0.057509                3   \n",
       "15           0.721649            0.632        0.069202               10   \n",
       "\n",
       "    split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0             0.116456            0.115288            0.114713   \n",
       "1             0.622785            0.659148            0.610973   \n",
       "2             0.622785            0.659148            0.610973   \n",
       "3             0.116456            0.115288            0.114713   \n",
       "4             0.756962            0.759398            0.773067   \n",
       "5             0.888608            0.917293            0.885287   \n",
       "6             0.888608            0.917293            0.885287   \n",
       "7             1.000000            1.000000            1.000000   \n",
       "8             0.893671            0.914787            0.902743   \n",
       "9             1.000000            1.000000            1.000000   \n",
       "10            1.000000            1.000000            1.000000   \n",
       "11            1.000000            1.000000            1.000000   \n",
       "12            0.997468            1.000000            1.000000   \n",
       "13            1.000000            1.000000            1.000000   \n",
       "14            1.000000            1.000000            1.000000   \n",
       "15            1.000000            1.000000            1.000000   \n",
       "\n",
       "    split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0             0.116915            0.116625          0.116000         0.000848  \n",
       "1             0.631841            0.610422          0.627034         0.017924  \n",
       "2             0.631841            0.610422          0.627034         0.017924  \n",
       "3             0.116915            0.116625          0.116000         0.000848  \n",
       "4             0.763682            0.751861          0.760994         0.007144  \n",
       "5             0.898010            0.875931          0.893026         0.014039  \n",
       "6             0.898010            0.875931          0.893026         0.014039  \n",
       "7             1.000000            1.000000          1.000000         0.000000  \n",
       "8             0.910448            0.885856          0.901501         0.010622  \n",
       "9             1.000000            1.000000          1.000000         0.000000  \n",
       "10            1.000000            1.000000          1.000000         0.000000  \n",
       "11            1.000000            1.000000          1.000000         0.000000  \n",
       "12            1.000000            0.997519          0.998997         0.001228  \n",
       "13            1.000000            1.000000          1.000000         0.000000  \n",
       "14            1.000000            1.000000          1.000000         0.000000  \n",
       "15            1.000000            1.000000          1.000000         0.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nAll scores on the grid:\")\n",
    "pd.DataFrame(grid_search_rbf.cv_results_)### ADD CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 6\n",
    "Report here the best SVM kernel and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T13:46:56.906095Z",
     "start_time": "2018-12-16T13:45:42.582024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM training error: 0.000000\n",
      "Best SVM test error: 0.203445\n"
     ]
    }
   ],
   "source": [
    "#get training and test error for the best SVM model from CV\n",
    "best_SVM = grid_search_rbf.best_estimator_ ### ADD CODE\n",
    "\n",
    "### ADD CODE : FIT MODEL\n",
    "best_SVM.fit(X_train,y_train)\n",
    "\n",
    "training_error = 1. - best_SVM.score(X_train,y_train)\n",
    "test_error = 1. - best_SVM.score(X_test,y_test) # may take a while ...\n",
    "\n",
    "print (\"Best SVM training error: %f\" % training_error)\n",
    "print (\"Best SVM test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More data\n",
    "Now let's do the same but using more data points for training.\n",
    "\n",
    "### TO DO 7\n",
    "Choose a new number of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T13:46:57.914053Z",
     "start_time": "2018-12-16T13:46:56.910057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels in training dataset:  [0 1 2 3 4 5 6 7 8 9]\n",
      "Frequencies in training dataset:  [204 199 202 200 192 222 170 208 198 205]\n"
     ]
    }
   ],
   "source": [
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "\n",
    "m_training = 2000 # TODO number of data points, adjust depending on the capabilities of your PC\n",
    "\n",
    "X_train, X_test = X[:m_training], X[m_training:]\n",
    "y_train, y_test = y[:m_training], y[m_training:]\n",
    "\n",
    "labels, freqs = np.unique(y_train, return_counts=True)\n",
    "print(\"Labels in training dataset: \", labels)\n",
    "print(\"Frequencies in training dataset: \", freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to use SVM with parameters obtained from the best model for $m_{training} =  500$. Since it may take a long time to run, you can decide to just let it run for some time and stop it if it does not complete. If you decide to do this, report it in the TO DO 9 cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T13:50:59.470157Z",
     "start_time": "2018-12-16T13:46:57.950055Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM training error: 0.004000\n",
      "Best SVM test error: 0.156259\n"
     ]
    }
   ],
   "source": [
    "#get training and test error for the best SVM model from CV\n",
    "\n",
    "### ADD CODE\n",
    "best_SVM.fit(X_train,y_train)\n",
    "\n",
    "training_error = 1. - best_SVM.score(X_train,y_train) \n",
    "# 4m executin time!\n",
    "test_error = 1. - best_SVM.score(X_test,y_test)\n",
    "\n",
    "print (\"Best SVM training error: %f\" % training_error)\n",
    "print (\"Best SVM test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for comparison, let's also use logistic regression (with standard parameters from scikit-learn, i.e. some regularization is included)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T13:51:51.006185Z",
     "start_time": "2018-12-16T13:50:59.486154Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   50.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best logistic regression training error: 0.037500\n",
      "Best logistic regression test error: 0.188138\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "### ADD CODE\n",
    "log_reg = linear_model.LogisticRegression(solver='newton-cg',n_jobs=-1,verbose=2)\n",
    "log_reg.fit(X_train,y_train)\n",
    "\n",
    "training_error = 1. - log_reg.score(X_train,y_train) \n",
    "test_error = 1. - log_reg.score(X_test,y_test)\n",
    "\n",
    "print (\"Best logistic regression training error: %f\" % training_error)\n",
    "print (\"Best logistic regression test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 9\n",
    "Compare and discuss:\n",
    "- the results from SVM with m=500 and with m=2000 training data points. If you stopped the SVM, include such aspect in your comparison.\n",
    "- the results of SVM and of Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "- SVM with fewer data points has null training error, but with $m=2000$ the test error decreases and the training error is different from zero (since it is more difficult to overfit) as one would expect to happen.\n",
    "- In this case, SVM with rbf kernel performs better than with any polynomial kernel and Logistic Regression, that is a linear model as well.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 10\n",
    "Plot an item of clothing that is missclassified by logistic regression and correctly classified by SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T13:51:51.558192Z",
     "start_time": "2018-12-16T13:51:51.010184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At index 1 of X_test:\n",
      "Classification by SVM:  3 (3 = Dress)\n",
      "Classification by LR:  1 (1 = Trousers)\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAEPtJREFUeJzt3V1sXOWdx/HfH4eEhLwnTuq8GEMhgYAgbKxoJZaFVQUKq0SkF0XNRZVFVYNQkSjqxSJu4GYltFraBWkpSpeoiUTTVmp5uUDdAlqJbQQNDiCSwm5wiENCjO28GYe8NI7/e+EJcsHn/5iZ8czEz/cjIdvzmzPzeMjPx+PnnPOYuwtAfi6p9wAA1AflBzJF+YFMUX4gU5QfyBTlBzJF+YFMUX4gU5QfyNSkWj7Z/Pnzva2trZZPmYVjx44VZk1NTeG2l1wS//wfHBwM85MnT4b5woULy37sSZPif56TJ08O8xx1dXXpyJEjNpb7VlR+M1sj6UlJTZL+090fj+7f1tamjo6OSp4So9i+fXthNmPGjHDbVN7X1xfmO3bsCPOHHnqoMIt+aEnS3Llzw7y1tTXMc9Te3j7m+5b9a7+ZNUn6D0l3SVohaYOZrSj38QDUViXv+VdL6nT3j9z9L5J+Jenu6gwLwHirpPyLJR0c8fWh0m1/xcw2mVmHmXWkfoUEUDuVlH+0Pyp85fxgd9/s7u3u3t7c3FzB0wGopkrKf0jS0hFfL5F0uLLhAKiVSsr/lqRrzOxKM5ss6buSXqrOsACMt7Kn+tx90MwekPRfGp7q2+Luf67ayPCF/v7+MN+5c2dhduedd4bbnjhxIsxvvPHGMO/u7g7z/fv3F2ZLliwJt3366afD/MEHHwzzlpaWMM9dRfP87v6ypJerNBYANcThvUCmKD+QKcoPZIryA5mi/ECmKD+QqZqez4/yzJo1K8zXrVtXmC1btizc9ty5c2E+NDQU5mvXrg3z6HoCqVN2Fy/+yqkiVZP6vlLXOZgIJv53CGBUlB/IFOUHMkX5gUxRfiBTlB/IFFN9E8Crr75amKWukLt8+fIwP3PmTJifOnUqzOfNm1eYpa78e/3114d56pTdaDovh6m8FF4BIFOUH8gU5QcyRfmBTFF+IFOUH8gU5QcyxTz/BLBiRfH6qNGlsyVp9erVFT33pZdeGuanT58uzFLLh6dO+UVl2PMDmaL8QKYoP5Apyg9kivIDmaL8QKYoP5Cpiub5zaxL0oCk85IG3b29GoPC1zN79uzC7Pjx4+G2fX19YZ7avrW1NcyjsaUuG14pztmPVeMgn39w9yNVeBwANcSPRiBTlZbfJf3BzHaZ2aZqDAhAbVT6a/8t7n7YzBZIesXM/tfdXx95h9IPhU1S+v0hgNqpaM/v7odLH3slPS/pK2eJuPtmd2939/bm5uZKng5AFZVdfjO73MxmXPhc0p2S9lRrYADGVyW/9i+U9LyZXXicX7r776syKgDjruzyu/tHkm6q4liylZrvTp0z39XVVZj19vaG277xxhthvmDBgjBPzaVH1xNIfd+dnZ1hvnLlyjDnuv0xXgEgU5QfyBTlBzJF+YFMUX4gU5QfyBSX7q6BaMpJSk/lpXz++eeF2dKlS8NtU1OB0Sm5krR3794w37ZtW2H26KOPhttWekQo03kxXh0gU5QfyBTlBzJF+YFMUX4gU5QfyBTlBzLFPP9FoLu7O8yXLVtWmK1atSrctr+/P8ynTJkS5qm5+FOnThVm0bgl6eOPPw7z1NhnzZoV5rljzw9kivIDmaL8QKYoP5Apyg9kivIDmaL8QKaY56+BSs8r37lzZ5hH1wPo6ekJtz127FiYX3bZZWH+5ptvhvmHH35YmKUu3T1t2rQwP3jwYJgzzx9jzw9kivIDmaL8QKYoP5Apyg9kivIDmaL8QKaS8/xmtkXSWkm97n5D6ba5kn4tqU1Sl6R73P34+A0zb9Ey15J08803l/3YfX19YX7TTfEq7Lt37w7z6DiBQ4cOhdumrhVw9OjRMEdsLHv+X0ha86XbHpb0mrtfI+m10tcALiLJ8rv765K+fBjY3ZK2lj7fKml9lccFYJyV+55/obt3S1Lp44LqDQlALYz7H/zMbJOZdZhZR+r9JYDaKbf8PWbWIkmlj4WrPbr7Zndvd/f2ShdeBFA95Zb/JUkbS59vlPRidYYDoFaS5Tez7ZLekLTczA6Z2fclPS7pDjP7UNIdpa8BXESS8/zuvqEg+laVx3LRGhoaCvPU+fwnT54M89R89ty5cwuzgYGBcNvBwcEwT123f+rUqWF+/vz5wqypqSncNnU+f2dnZ5hH/18qvcbCRMArAGSK8gOZovxApig/kCnKD2SK8gOZ4tLdVVDptFHqlN2zZ8+GeTQllprqSx1yHV0WXIqX4JbiS4MfPnw43La1tTXMU6979Nzz588Pt80Be34gU5QfyBTlBzJF+YFMUX4gU5QfyBTlBzLFPH8DSM21T5oU/29KzcVHjh+Pr7g+e/bsME+dbhydtvv++++H2956661hvmjRojDv7u4uzJjnZ88PZIvyA5mi/ECmKD+QKcoPZIryA5mi/ECmmOdvAKnz+VNz0tF57f39/eG206dPD/Po0tuSNHPmzDBfvnx5YbZv375w29QKT7t27Qrz1DEKuWPPD2SK8gOZovxApig/kCnKD2SK8gOZovxAppLz/Ga2RdJaSb3ufkPptsck/UDShRPRH3H3l8drkBPd6dOnw3zy5Mll5wcPHgy3TS2TnZIa22233VaYPfXUU+G29957b5ivWLEizNevXx/muRvLnv8XktaMcvtP3X1l6T+KD1xkkuV399clFS99AuCiVMl7/gfM7D0z22Jmc6o2IgA1UW75fybpm5JWSuqW9ETRHc1sk5l1mFlH6lp1AGqnrPK7e4+7n3f3IUk/l7Q6uO9md2939/bUiRoAaqes8ptZy4gvvy1pT3WGA6BWxjLVt13S7ZLmm9khSY9Kut3MVkpySV2S7hvHMQIYB8nyu/uGUW5+dhzGkq1K16mPzslPzfPPmzcvzM+dOxfmn332WZj39vYWZk88UfinIknp8/Xfe++9MB8cHAzz3HGEH5Apyg9kivIDmaL8QKYoP5Apyg9kikt318DQ0FCY9/T0hPnKlSvLfu69e/eG+V133VX2Y0vp5cHfeeedwuzaa68Nt50xY0bZjy1Ja9aMdjLqsNQUZiXLnl8s2PMDmaL8QKYoP5Apyg9kivIDmaL8QKYoP5Ap5vlrILVMdurS3XPnzg3zU6dOFWapS6ctXLgwzI8ePRrmU6dODfPrrrsuzCPTpk0L8+j7luLlxU+ePBluO2fOxL8sJXt+IFOUH8gU5QcyRfmBTFF+IFOUH8gU5QcyxTx/DXzyySdhHs1HS+m5+Gi++8iRI+G2LS0tYe7uYZ4SXZb8iiuuCLdNzfMvWLAgzKPjKy65hP0erwCQKcoPZIryA5mi/ECmKD+QKcoPZIryA5lKzvOb2VJJ2yR9Q9KQpM3u/qSZzZX0a0ltkrok3ePux8dvqBev1Dx/yvz588O8s7OzMEutGbBo0aIwTy2DPXPmzDB/5plnCrP77rsv3DZ1Xf6UgYGBwiz1uuRgLHv+QUk/dvfrJP2tpB+a2QpJD0t6zd2vkfRa6WsAF4lk+d29293fLn0+IOkDSYsl3S1pa+luWyWtH69BAqi+r/We38zaJN0s6U+SFrp7tzT8A0JSfKwlgIYy5vKb2XRJv5X0I3f/7Gtst8nMOsysI3U9OQC1M6bym9mlGi7+c+7+u9LNPWbWUspbJPWOtq27b3b3dndvb25ursaYAVRBsvxmZpKelfSBu/9kRPSSpI2lzzdKerH6wwMwXsZySu8tkr4nabeZvVu67RFJj0v6jZl9X9LHkr4zPkO8+B07dizMU9NOqaWq9+3bV5ilTotNLUWdylPf23PPPVf2tqlTmVOiqb4pU6ZU9NgTQbL87v5HSVYQf6u6wwFQKxzhB2SK8gOZovxApig/kCnKD2SK8gOZ4tLdVXD27NkwT10++8CBA2GempOOLo+dWt47dQnr1Dz/p59+GuaVSC3B3dTUFObR6576f5Y6PmIiYM8PZIryA5mi/ECmKD+QKcoPZIryA5mi/ECmmOevgf3794f59OnTK3r86BLXra2tFT126jiA1Dn5586dK8xSc+2VHoMQHSeQGvecOXPCfCJgzw9kivIDmaL8QKYoP5Apyg9kivIDmaL8QKaY56+CM2fOVLT91VdfXdH2e/bsKczWrVsXblvpOfPnz58P82guPzVPHx0jMBY9PT0VbT/RsecHMkX5gUxRfiBTlB/IFOUHMkX5gUxRfiBTyXl+M1sqaZukb0gakrTZ3Z80s8ck/UBSX+muj7j7y+M10EbW2dkZ5l1dXWHe1tYW5kNDQ2He3NxcmC1fvjzctr+/P8xTc/GTJ08O84GBgcIsdW381DEIKUePHi3MUmsh5GAsB/kMSvqxu79tZjMk7TKzV0rZT93938ZveADGS7L87t4tqbv0+YCZfSBp8XgPDMD4+lrv+c2sTdLNkv5UuukBM3vPzLaY2ajXPTKzTWbWYWYdfX19o90FQB2MufxmNl3SbyX9yN0/k/QzSd+UtFLDvxk8Mdp27r7Z3dvdvT16bwqgtsZUfjO7VMPFf87dfydJ7t7j7ufdfUjSzyWtHr9hAqi2ZPnNzCQ9K+kDd//JiNtbRtzt25KKTy0D0HDG8tf+WyR9T9JuM3u3dNsjkjaY2UpJLqlL0n3jMsKLwFVXXRXmqam6lF27doX57t27C7PUEt2VnvY6derUMI8ukZ2ayjtx4kSYp17XgwcPFmZ79+4Nt12yZEmYTwRj+Wv/HyXZKFGWc/rARMERfkCmKD+QKcoPZIryA5mi/ECmKD+QKS7dXQWp5ZxfeOGFMO/u7g7zAwcOhPn9999fmF155ZXhtpMmxf8EUvP4qeMIorn8tWvXhtumrFmzJsx37NhRmK1ataqi554I2PMDmaL8QKYoP5Apyg9kivIDmaL8QKYoP5Apc/faPZlZn6SRk9bzJR2p2QC+nkYdW6OOS2Js5arm2K5w9zFdL6+m5f/Kk5t1uHt73QYQaNSxNeq4JMZWrnqNjV/7gUxRfiBT9S7/5jo/f6RRx9ao45IYW7nqMra6vucHUD/13vMDqJO6lN/M1pjZ/5lZp5k9XI8xFDGzLjPbbWbvmllHnceyxcx6zWzPiNvmmtkrZvZh6WN8PnFtx/aYmX1Seu3eNbN/rNPYlprZf5vZB2b2ZzN7sHR7XV+7YFx1ed1q/mu/mTVJ2ivpDkmHJL0laYO7v1/TgRQwsy5J7e5e9zlhM/t7SSclbXP3G0q3/aukY+7+eOkH5xx3/+cGGdtjkk7We+Xm0oIyLSNXlpa0XtI/qY6vXTCue1SH160ee/7Vkjrd/SN3/4ukX0m6uw7jaHju/rqkL696cbekraXPt2r4H0/NFYytIbh7t7u/Xfp8QNKFlaXr+toF46qLepR/saSRS6kcUmMt+e2S/mBmu8xsU70HM4qFpWXTLyyfvqDO4/my5MrNtfSllaUb5rUrZ8XraqtH+Udb/aeRphxucfe/kXSXpB+Wfr3F2Ixp5eZaGWVl6YZQ7orX1VaP8h+StHTE10skHa7DOEbl7odLH3slPa/GW32458IiqaWPvXUezxcaaeXm0VaWVgO8do204nU9yv+WpGvM7Eozmyzpu5JeqsM4vsLMLi/9IUZmdrmkO9V4qw+/JGlj6fONkl6s41j+SqOs3Fy0srTq/No12orXdTnIpzSV8e+SmiRtcfd/qfkgRmFmV2l4by8NX9n4l/Ucm5ltl3S7hs/66pH0qKQXJP1GUqukjyV9x91r/oe3grHdruFfXb9YufnCe+waj+3vJP2PpN2SLizl+4iG31/X7bULxrVBdXjdOMIPyBRH+AGZovxApig/kCnKD2SK8gOZovxApig/kCnKD2Tq/wGp8ihlQ+MhpgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 3\n"
     ]
    }
   ],
   "source": [
    "LR_prediction = log_reg.predict ### ADD CODE\n",
    "SVM_prediction = best_SVM.predict ### ADD CODE\n",
    "\n",
    "### ADD CODE TO SEARCH AND VISUALIZE\n",
    "for i in range(X_test.shape[0]):\n",
    "    # Search for the first sample that is missclassified by LM but correctly classified by SVM\n",
    "    if SVM_prediction(X_test[i,:].reshape(1,-1)).item() == y_test[i] and LR_prediction(X_test[0,:].reshape(1,-1)).item() != y_test[i]:\n",
    "        print('At index',i,'of X_test:')\n",
    "        print('Classification by SVM: ', SVM_prediction(X_test[i,:].reshape(1,-1)).item(),'(3 = Dress)')\n",
    "        print('Classification by LR: ', LR_prediction(X_test[i,:].reshape(1,-1)).item(),'(1 = Trousers)')\n",
    "        plot_input(X_test,y_test,i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 11\n",
    "Plot the confusion matrix for the SVM classifier and for logistic regression.\n",
    "The confusion matrix has one column for each predicted label and one row for each true label. \n",
    "It shows for each class in the corresponding row how many samples belonging to that class gets each possible output label.\n",
    "Notice that the diagonal contains the correctly classified samples, while the other cells correspond to errors.\n",
    "You can obtain it with the sklearn.metrics.confusion_matrix function (see the documentation).\n",
    "Try also to normalize the confusion matrix by dividing each row for the number of samples in each class in order to measure the accuracy on each single class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T13:55:47.742327Z",
     "start_time": "2018-12-16T13:51:51.566186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and frequencies in test set:  [5796 5801 5798 5800 5808 5778 5830 5792 5802 5795]\n",
      "\n",
      " Confusion matrix SVM  \n",
      " \n",
      " [[4752    3  121  264   16    4  579    0   57    0]\n",
      " [  41 5466   75  186    9    0   21    0    3    0]\n",
      " [ 123    2 4392   59  680    3  493    0   46    0]\n",
      " [ 259   39   74 4981  259    0  173    0   15    0]\n",
      " [  30    8  683  184 4477    2  394    0   29    1]\n",
      " [   3    0    3   10    0 5352    8  260   41  101]\n",
      " [ 988    6  748  165  589    0 3226    0  107    1]\n",
      " [   0    0    0    0    0  218    0 5252   11  311]\n",
      " [  31    1   39   35   19   36   65   22 5548    6]\n",
      " [   2    0    3    2    0  105    1  189    2 5491]]\n",
      "\n",
      " Confusion matrix LR  \n",
      " \n",
      " [[4482   15  150  352   39   11  619    5  121    2]\n",
      " [  30 5469   79  175   13    1   27    2    5    0]\n",
      " [ 151    3 4153   75  833   16  507    0   60    0]\n",
      " [ 245   44   70 4885  323    0  187    1   43    2]\n",
      " [  36   14  804  205 4165    7  533    1   42    1]\n",
      " [  15    1    6   24    2 5075   14  368   54  219]\n",
      " [ 943   13  852  221  722   14 2895    2  166    2]\n",
      " [   0    0    0    0    0  271    0 5115   19  387]\n",
      " [  62    3   49   90   33   76   81   46 5351   11]\n",
      " [   5    0    0    6    1   84    6  192    3 5498]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=2, suppress=True,floatmode='fixed') # for better aligned printing of confusion matrix\n",
    "\n",
    "u, counts = np.unique(y_test, return_counts=True)\n",
    "print(\"Labels and frequencies in test set: \", counts)\n",
    "# 4m to run!!\n",
    "confusion_SVM = skm.confusion_matrix(y_test,SVM_prediction(X_test)) ### ADD CODE\n",
    "\n",
    "print(\"\\n Confusion matrix SVM  \\n \\n\", confusion_SVM)\n",
    "\n",
    "### ADD CODE TO NORMALIZE CONFUSION MATRIX AND PRINT THE NORMALIZED MATRIX\n",
    "\n",
    "confusion_LR = skm.confusion_matrix(y_test,LR_prediction(X_test)) ### ADD CODE\n",
    "\n",
    "print(\"\\n Confusion matrix LR  \\n \\n\", confusion_LR)\n",
    "\n",
    "### ADD CODE TO NORMALIZE CONFUSION MATRIX AND PRINT THE NORMALIZED MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T20:48:17.980466Z",
     "start_time": "2018-12-16T20:48:17.936458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Normalized Confusion matrix SVM  \n",
      " \n",
      " [[0.82 0.00 0.02 0.05 0.00 0.00 0.10 0.00 0.01 0.00]\n",
      " [0.01 0.94 0.01 0.03 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.02 0.00 0.76 0.01 0.12 0.00 0.08 0.00 0.01 0.00]\n",
      " [0.04 0.01 0.01 0.86 0.04 0.00 0.03 0.00 0.00 0.00]\n",
      " [0.01 0.00 0.12 0.03 0.77 0.00 0.07 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.93 0.00 0.04 0.01 0.02]\n",
      " [0.17 0.00 0.13 0.03 0.10 0.00 0.55 0.00 0.02 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.04 0.00 0.91 0.00 0.05]\n",
      " [0.01 0.00 0.01 0.01 0.00 0.01 0.01 0.00 0.96 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.02 0.00 0.03 0.00 0.95]]\n",
      "\n",
      " Normalized Confusion matrix LR  \n",
      " \n",
      " [[0.77 0.00 0.03 0.06 0.01 0.00 0.11 0.00 0.02 0.00]\n",
      " [0.01 0.94 0.01 0.03 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.03 0.00 0.72 0.01 0.14 0.00 0.09 0.00 0.01 0.00]\n",
      " [0.04 0.01 0.01 0.84 0.06 0.00 0.03 0.00 0.01 0.00]\n",
      " [0.01 0.00 0.14 0.04 0.72 0.00 0.09 0.00 0.01 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.88 0.00 0.06 0.01 0.04]\n",
      " [0.16 0.00 0.15 0.04 0.12 0.00 0.50 0.00 0.03 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.05 0.00 0.88 0.00 0.07]\n",
      " [0.01 0.00 0.01 0.02 0.01 0.01 0.01 0.01 0.92 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.01 0.00 0.03 0.00 0.95]]\n"
     ]
    }
   ],
   "source": [
    "norm_confusion_SVM = confusion_SVM / confusion_SVM.sum(axis=1)\n",
    "print(\"\\n Normalized Confusion matrix SVM  \\n \\n\", norm_confusion_SVM)\n",
    "norm_confusion_LR = confusion_LR / confusion_LR.sum(axis=1)\n",
    "print(\"\\n Normalized Confusion matrix LR  \\n \\n\", norm_confusion_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T13:55:49.250295Z",
     "start_time": "2018-12-16T13:55:47.814289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiUAAAHwCAYAAAB5dh/qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3XvcpXVd7//Xe4bzSZBBk5OQob948EjECVPKTNDADMyfGbTVjZlTlqZptbXannbHXdvKZFez1TyjCNImxdAsjwExoKbDQYFEBlQYAQUBYeCz/7iu0cXNfVj3sK5Z67ru15PHenCvta77+/2sNffhc3++p1QVkiRJ07Zq2gFIkiSBSYkkSZoRJiWSJGkmmJRIkqSZYFIiSZJmgkmJJEmaCSYlWrGSvDbJu9qPD05yW5LVE+7jK0mOm2Sby+j7D5JsTvL1B9BGJ+/L9pbkd5O8edpxSFqcSYk60/5C/kaS3Uce++UkH59iWPOqqq9W1R5Vdc/27DfJ0UnOTXJLkpuS/HuS50+g3YOAVwCHV9UPbGs7Xb4vSar9+thh5LEdktyQZKwNlJI8Kcmmpa6rqj+qql/exjhfkOTyJLe28X4oyZ5JXpXkk/NcvybJXUmOSHJq+zrfMOeaZ7SPv21bYpKGyqREXdsBeOkDbSSNQX29Jnk88C/AJ4AfAvYFXgScMIHmHw58s6pumEBbXbqF+77epwE3T7KD0aRnGz73J4E/Ak6pqj2BHwbOaJ9+J/CEJIfO+bSTgS9U1Rfb+1cBvzAnjucBX9rWuKShGtQPec2kPwN+K8ne8z2Z5AlJLkryrfb/Txh57uNJ/jDJZ4DbgR9sH/uDJP/WDiv8Y5J9k7w7ybfbNg4ZaeOvklzbPndxkp9YII5D2r9cd0jy+Lbtrbc7k3ylvW5VklcmuSrJN5OckeTBI+08N8k17XO/N8Z78/aq+tOq2lyNi6vq2SPtvTDJlW0V5Zwk+488V0l+NcmXk9yc5LQ2eTsO+Ciwfxv/2+arKIwOLbUVmw3t+/SNrX/Zj74v7f392zhuauN64Uh7r23fj3e0VYWNSdYu8R68k+YX9FbPA94xJ87nJ7msbfPqJL/SPr478OGR13lbG99rk5yZ5F1Jvg2cmvsO1f1C285e7f0Tknw9yX7zxPejwPlV9VmAqrqpqt5eVbdW1SaapPK5cz7necDbR+5/HfgC8NNtfw8GngCcs8R7I604JiXq2gbg48BvzX2i/eH8IeCNNFWCNwAfSrLvyGXPBdYBewLXtI+d3D5+APAI4Hzg74EHA5cBrxn5/IuAI9vn3gO8P8kuiwVcVee3QxZ7APsAFwCnt0//BvAM4CeB/Wn+qj+tfT2HA3/TxrZ/+5oOnK+PJLsBjwfOXCiOJE8G/hh4NvCw9vW/d85lT6f5xfno9rqfrqp/pqk+XN++jlMXe72tvwL+qqr2onlPz1jgutOBTe3rexbwR0mOHXn+xDbGvWl+6b5piX7/AXhikr3bxPUngP8755ob2te5F/B84C+SHFVV35nzOveoquvbzzmJ5r3dG3j3aGNV9T6ar5k3tl9rbwF+uapunCe+C4GfTvK6JMck2XnO829nJClJ8iiar7fT51z3Dr6ffJ3cvsbvLviuSCuUSYm2h1cDL5nnL9GfAb5cVe+sqi1VdTpwOfCzI9e8rao2ts/f3T7291V1VVV9i+Yv5auq6p+ragvwfuAxWz+5qt5VVd9sP/9/ATsDj1pG7G8EvgNsrXr8CvB7VbWpqr4LvBZ4VltJeBbwwar6ZPvcfwfuXaDdfWi+/762SN//BXhrVV3Stvcq4PGjlSDgT6rqlqr6KvCvNL8Qt8XdwA8lWVNVt1XVBXMvSDNP5ceB/1ZVd1bV54A3c99Kwaer6tx2Dso7aZKlxdwJ/CPwCzS/rM9pH/ueqvpQ++9dVfUJ4CM0yctizq+qf6iqe6vqjnme/3XgyTQJ8z9W1Qfna6SqPgU8EziKJoH+ZpI35PsTf88GHjpS4Xse8OF5EpyzgScleRDzVIMkNUxK1Ll2bP2DwCvnPLU/369+bHUNTQVkq2vnafIbIx/fMc/9PbbeSfKKtvT/rSS3AA8C1owTdztM8CTgF6tqa3LxcODsNBNTb6GpzNwDPLR9Pd+Lt/1L/psLNH8zTcLysEVCuM/7U1W3te2Nvj+jK2tuZ+S1L9MLgEcCl7dDYE9fIJ6bqurWkcfm/nvNjWeXLD2nY2sVYd5f1u3wygXtkNEtNPNOlvo3nO/r5nuq6haaBPYI4H8tce2Hq+pnaaptJwGnAr/cPnd7287zkoQmkXz7PG3cQZPU/D6wpqo+s0T80opkUqLt5TXAC7nvL7DraX7JjzoYuG7k/jYfY93OH/lvNMMa+1TV3sC3gIz5uf8DOKmtyGx1LXBCVe09ctulqq6jqXocNNLGbjRDOPfT/jI7H/j/FwnjPu9PO4diX+77/ozrO8BuI22tBr5XuaqqL1fVKcBDgD8FzszIqqmReB6cZM+Rx+b+e22LT9EkZw8FPj36RDtcchbw58BD23/Dc/n+v+FCXx+Lft0kORL4JZphljeOE2RbdfkYzTySI0aeejvN19hTaIYZ56260CRcr6CpIEmah0mJtouquhJ4H82cjK3OBR6Z5BfTTDD9BeBwFv6hvlx7AluAG4EdkryaZl7CotphivcBz6uquSsk/hb4wyQPb6/dL8lJ7XNnAk9P8uNJdgJez+LfY79DMwnzt7fOo0ny6CRb5428B3h+kiPbX85/BFxYVV9Z8pXf35doqhY/k2RHmr/Yvzc/IslzkuzXVoRuaR++zzLgqroW+Dfgj5PskuRHaCos95mzsVxVVTRDdie2H4/aqY3zRmBLkhOAp448/w1g33ZYZCztnKJ3Ab9LM0flgCS/tsC1JyU5Ock+aRxNM59odHjrUzTv2XrgvVV11wJdf4ImcfnrcWOVVhqTEm1Prwe+99d3VX2TZgLjK2iGJX4HeHpVbZ5Qf+fRzDn5Es0ww50sUdZvHQv8AE21YOuqjo3tc39FM+/hI0lupfnl9Lj29WykmavwHpqqyc00k0LnVVX/RjOv4cnA1UluovnFdm77/Mdo5qWc1bb3CJp5F8vWVnt+jWYOyHU0lZPR2I4HNia5rX2NJ1fVnfdrCE4BDqGpmpwNvKaqProtMc2Jb2P7/s19/FaaRPYMmvfzFxlZtVJVl9NUO65uh9T2n9vGPP4Y2FRVf9PO1XkO8AdJDpvn2ptpKnxfBr5Nk8z8WVV9LxFrE6l30FS1Fpwr0s6J+VhV3TRGjNKKlPv/YSJJkrT9WSmRJEkzwaREkiTNBJMSSZI0E0xKJEnSTDApkSRJM2GbT8/sQnbes1btPtZmm1N35KHz7ok1s/q0xurenq0IW50l92LTNrr7nv58Ley4ul9fB/15Z8fY7XCGXHPNV9i8efN2C3n1Xg+v2jLfSQoPTN1x43lVdfzEG17CTCUlq3Zfw67HvWbpC2fAZ95z6rRDWJYt9yx0BMvsuWtLf2IF2G3nmfo2GpQbv92fM+v222vuWX2z7d57+5OWrFrVn7TkmMctdTD2ZNWWO9j5Uc9e+sJluvNzp02lQuBPU0mSeiuQ4czEGM4rkSRJvWalRJKkvgowoHltVkokSdJMsFIiSVKfDWhOiUmJJEl95vCNJEnSZFkpkSSpt1wSLEmSNHFWSiRJ6rMBzSkxKZEkqa+CwzeSJEmTZqVEkqTeyqCGb6yUSJKkmWClRJKkPhvQnBKTEkmS+szhm/EkOT7JFUmuTPLKLvuSJEn91lmlJMlq4DTgKcAm4KIk51TVpV31KUnSyuKOruM6Griyqq6uqruA9wInddifJEnqsS7nlBwAXDtyfxPwuA77kyRpZQnOKRnTfO9S3e+iZF2SDUk21Hdv7TAcSZI0y7qslGwCDhq5fyBw/dyLqmo9sB5g9YMPvV/SIkmSFjGgOSVdJiUXAYclORS4DjgZ+MUO+5MkaYUZ1kTXzpKSqtqS5MXAecBq4K1VtbGr/iRJUr91unlaVZ0LnNtlH5IkrWirnOgqSZI0UW4zL0lSXwXnlEiSpBnhPiWSJEmTZaVEkqTeGtaS4OG8EkmS1GtWSiRJ6rMBzSkxKZEkqc8cvpEkSZosKyWSJPVVMqjhGyslkiRpJlgpkSSpzwY0p8SkRJKkPnP4RpIkabKslEiS1Fvu6CpJkjRxM1UpefSh+/KZd//XaYcxln1+7GXTDmFZNv/bX0w7hLGtXjWc8VE9MPvttfO0QxisVX6fDYdzSiRJkiZrpiolkiRpGcKg5pSYlEiS1FtOdJUkSZo4KyWSJPWZE10lSZImy0qJJEl9NqA5JSYlkiT1mcM3kiRJk2WlRJKkvopLgiVJkibOSokkSX02oDklJiWSJPVYBpSUOHwjSZJmgpUSSZJ6KlgpkSRJmjgrJZIk9VXa20B0VilJ8tYkNyT5Yld9SJKk4ehy+OZtwPEdti9J0goXksnfpqWz4Zuq+mSSQ7pqX5IkOdFVkiRp4qY+0TXJOmAdwEEHHzzlaCRJ6hcrJRNUVeuram1VrV2zZr9phyNJkqZk6kmJJEnadtOa6Jrk+CRXJLkyySvnef7gJP+a5LNJ/iPJ05Zqs8slwacD5wOPSrIpyQu66kuSpBUpHd2W6jZZDZwGnAAcDpyS5PA5l/0+cEZVPQY4GfjfS7Xb5eqbU7pqW5IkTdXRwJVVdTVAkvcCJwGXjlxTwF7txw8Crl+q0alPdJUkSdsmTG1fkQOAa0fubwIeN+ea1wIfSfISYHfguKUadU6JJEmaa02SDSO3dXOeny8Tqjn3TwHeVlUHAk8D3plk0bzDSokkST3WUaVkc1WtXeT5TcBBI/cP5P7DMy+g3dm9qs5PsguwBrhhoUatlEiS1GNTWn1zEXBYkkOT7EQzkfWcOdd8FTi2jfGHgV2AGxdr1KREkiQtS1VtAV4MnAdcRrPKZmOS1yc5sb3sFcALk3weOB04tarmDvHch8M3kiT12LR2dK2qc4Fz5zz26pGPLwWOWU6bVkokSdJMsFIiSVJfjbnZWV9YKZEkSTPBSokkST02pFOCTUokSeqpKe7o2gmHbyRJ0kywUiJJUo9ZKZEkSZowKyWSJPXZcAolJiWSJPVWHL6RJEmauJmrlNxz76Jn9cyMmy/4y2mHsCyH/vpZ0w5hbFf99TOnHcKyfO2WO6cdwtgetvcu0w5hWW667a5phzC2B++x07RDWJZ7e/KzFmDVquFUArpgpUSSJGnCZq5SIkmSxjekSolJiSRJPeWOrpIkSR2wUiJJUp8Np1BipUSSJM0GKyWSJPWVm6dJkiRNnpUSSZJ6bEiVEpMSSZJ6bEhJicM3kiRpJlgpkSSpz4ZTKLFSIkmSZoOVEkmSemxIc0pMSiRJ6qnEs28kSZImzkqJJEk9ZqVkDEkOSvKvSS5LsjHJS7vqS5Ik9V+XlZItwCuq6pIkewIXJ/loVV3aYZ+SJK0oQ6qUdJaUVNXXgK+1H9+a5DLgAMCkRJKkSRlOTrJ9JromOQR4DHDh9uhPkiT1T+cTXZPsAZwFvKyqvj3P8+uAdQAHHXRw1+FIkjQoQxq+6bRSkmRHmoTk3VX1gfmuqar1VbW2qtau2W+/LsORJEkzrLNKSZrU7S3AZVX1hq76kSRpxYqVknEdAzwXeHKSz7W3p3XYnyRJ6rEuV998mkHNCZYkabYEGFChxB1dJUnqL8++kSRJmjgrJZIk9diACiVWSiRJ0mywUiJJUo8NaU6JSYkkSX0Vh28kSZImzkqJJEk9FWDVquGUSqyUSJKkmWClRJKkHhvSnBKTEkmSemxIq28cvpEkSTPBSokkSX3lkmBJkqTJs1IiSVJPBeeUSJIkTdxMVUqq4O57atphjGX1qn7EudWVf/3MaYcwtn1/7k3TDmFZrn//r007hMHaY5eZ+hE1KEPacGtly6AqJX7HS5LUYwPKSRy+kSRJs8FKiSRJPTak4RsrJZIkaSZYKZEkqa8GtnmaSYkkST3lPiWSJEkdsFIiSVKPDahQYqVEkiTNBislkiT12JDmlJiUSJLUYwPKSRy+kSRJs8FKiSRJfZVhDd9YKZEkSTPBSokkST3VbJ427Sgmx0qJJEmaCVZKJEnqrQxqTklnSUmSXYBPAju3/ZxZVa/pqj9JklaiAeUknVZKvgs8uapuS7Ij8OkkH66qCzrsU5Ik9VRnSUlVFXBbe3fH9lZd9SdJ0ko0pOGbTie6Jlmd5HPADcBHq+rCLvuTJEn91WlSUlX3VNWRwIHA0UmOmHtNknVJNiTZsHnzjV2GI0nSsKSZUzLp27RslyXBVXUL8HHg+HmeW19Va6tq7Zo1+22PcCRJGoRmn5JM/DYtnSUlSfZLsnf78a7AccDlXfUnSZL6rcvVNw8D3p5kNU3yc0ZVfbDD/iRJWnGGNNG1y9U3/wE8pqv2JUnSsLijqyRJPTagQoln30iS1GfTmuia5PgkVyS5MskrF7jm2UkuTbIxyXuWatNKiSRJWpZ2vuhpwFOATcBFSc6pqktHrjkMeBVwTFXdnOQhS7VrUiJJUl9Nb1+Ro4Erq+pqgCTvBU4CLh255oXAaVV1M0BV3bBUow7fSJKk5ToAuHbk/qb2sVGPBB6Z5DNJLkhyv73K5rJSIklST4XONjtbk2TDyP31VbX+Pl3f39zz7XYADgOeRLOz+6eSHNFuqDovkxJJknqso+GbzVW1dpHnNwEHjdw/ELh+nmsuqKq7gf9McgVNknLRQo06fCNJkpbrIuCwJIcm2Qk4GThnzjX/APwUQJI1NMM5Vy/WqJUSSZJ6bNUUZrpW1ZYkLwbOA1YDb62qjUleD2yoqnPa556a5FLgHuC3q+qbi7VrUiJJkpatqs4Fzp3z2KtHPi7g5e1tLCYlkiT1mDu6SpIkTZiVEkmSeirxlGBJkjQjVg0nJ3H4RpIkzQYrJZIk9diQhm+slEiSpJkwU5WSBHbZsR95Ut8y0xu+dee0Qxjb18/8tWmHsCyHvfisaYcwtq/+3bOnHcKy3HHXPdMOYWw77dCPn11bNVtI9EPfft5ub0N6e2YqKZEkSeMLzaF8Q9Gv1F6SJA2WlRJJknrMJcGSJEkTZqVEkqS+SgY1EdikRJKkHhtQTuLwjSRJmg1WSiRJ6qkAqwZUKrFSIkmSZoKVEkmSemxAhRIrJZIkaTZYKZEkqcdcEixJkqYucfhGkiRp4qyUSJLUYy4JliRJmjArJZIk9dhw6iTbISlJshrYAFxXVU/vuj9JklaSIa2+2R7DNy8FLtsO/UiSpB5bsFKSZK/FPrGqvr1U40kOBH4G+EPg5cuOTpIkLag5+2baUUzOYsM3G4HivsNVW+8XcPAY7f8l8DvAntsaoCRJWhkWTEqq6qAH0nCSpwM3VNXFSZ60yHXrgHUABx08Tp4jSZIASFbenJIkJyf53fbjA5M8doxPOwY4MclXgPcCT07yrrkXVdX6qlpbVWvXrNlvGaFLkqStu7pO8jYtSyYlSd4E/BTw3Pah24G/XerzqupVVXVgVR0CnAz8S1U95wHEKkmSBmycJcFPqKqjknwWoKpuSrJTx3FJkqQxDGn4Zpyk5O4kq2gmt5JkX+De5XRSVR8HPr7c4CRJ0soxTlJyGnAWsF+S1wHPBl7XaVSSJGlJK2lJMABV9Y4kFwPHtQ/9fFV9sduwJEnSSjPuNvOrgbtphnA8xE+SpBkxpDkl46y++T3gdGB/4EDgPUle1XVgkiRpaengNi3jVEqeAzy2qm4HSPKHwMXAH3cZmCRJWlnGSUqumXPdDsDV3YQjSZLGlcCqAQ3fLHYg31/QzCG5HdiY5Lz2/lOBT2+f8CRJ0kqxWKVk6wqbjcCHRh6/oLtwJEnScgyoULLogXxv2Z6BSJKk5RvS6psl55QkeQTwh8DhwC5bH6+qR3YYlyRJWmHG2XPkbcDf06wSOgE4g+bUX0mSNGUr6pRgYLeqOg+gqq6qqt+nOTVYkiRpYsZZEvzdNANWVyX5VeA64CHdhiVJkpYSsjKWBI/4TWAP4Ddo5pY8CPilLoOSJEljmPJwy6SNcyDfhe2HtwLP7TYcSZK0Ui22edrZNJulzauqntlJRJIkaWwrZUnwm7ZbFK0wrDd3ljxs712Wvkjb5Kt/9+xphzC2fX7ildMOYVlu/tSfTDuEsd3+3S3TDmFZdt1p9bRDGNuWe+6ddghjW/AveY1lsc3TPrY9A5EkScs3zjLavhjSa5EkST02zuobSZI0g4Y27WHspCTJzlX13S6DkSRJy7NqODnJ0sM3SY5O8gXgy+39Ryf5684jkyRJK8o4c0reCDwd+CZAVX0et5mXJGkmrMrkb1N7LeNcU1XXzHnsni6CkSRJK9c4c0quTXI0UElWAy8BvtRtWJIkaSnNqb7DmVQyTlLyIpohnIOBbwD/3D4mSZKmbEgTXcc5++YG4OTtEIskSVrBlkxKkvwf5tk5t6rWdRKRJEka24BGb8YavvnnkY93AX4OuLabcCRJ0ko1zvDN+0bvJ3kn8NHOIpIkSWMJsGpApZJt2Wb+UODhkw5EkiQt35AOsRtnTsnNfH9OySrgJqBf559LkqSZt2hSkmbx86OB69qH7q2q+016lSRJ0zGg0ZvFqz5tAnJ2Vd3T3kxIJElSJ8aZU/LvSY6qqkuW23iSrwC30mxLv6Wq1i63DUmSNL8kK2Oia5IdqmoL8OPAC5NcBXyHZrJvVdVRY/bxU1W1+YGHKkmShmyxSsm/A0cBz9hOsUiSpGUaUKFk0aQkAFV11QNov4CPJCng76pq/QNoS5IkzbFSzr7ZL8nLF3qyqt4wRvvHVNX1SR4CfDTJ5VX1ydELkqwD1gEcdPDB48QsSZIGaLGkZDWwB23FZFtU1fXt/29IcjZwNPDJOdesB9YDPPaxa13dI0nSmFbSjq5fq6rXb2vDSXYHVlXVre3HTwW2uT1JkjRsS84peQAeCpzd7L/GDsB7quqfHmCbkiRpxIAKJYsmJcc+kIar6mqa3WAlSVIXMqyJrgvu6FpVN23PQCRJ0sq2LacES5KkGZEHPNtidgzpxGNJktRjVkokSeqpZknwtKOYHJMSSZJ6bEhJicM3kiRp2ZIcn+SKJFcmeeUi1z0rSSVZu1SbVkokSeqxTGGjkiSrgdOApwCbgIuSnFNVl865bk/gN4ALx2nXSokkSVquo4Erq+rqqroLeC9w0jzX/Q/gfwJ3jtOoSYkkST21daLrpG9jOAC4duT+pvax78eWPAY4qKo+OO7rcfhGkiTNtSbJhpH769sDdLeaL3X53qG6SVYBfwGcupxOTUokSeqrdHb2zeaqWmxi6ibgoJH7BwLXj9zfEzgC+Hg75+UHgHOSnFhVo8nOfZiUSJLUY6umcyLfRcBhSQ4FrgNOBn5x65NV9S1gzdb7ST4O/NZiCQk4p0SSJC1TVW0BXgycB1wGnFFVG5O8PsmJ29qulRJJknpqmju6VtW5wLlzHnv1Atc+aZw2rZRIkqSZYKVEkqQem86Ukm6YlEiS1Fth1byrc/tpppKSO7fcy1XfuG3aYYzlEQ/dY9ohLMt1N90x7RDGtt9eO087hGW55fa7px3C2G7+1J9MO4RlOeVti07Unymnn7rksR4zZcs99047hLHtsLo/Mw2Gkx5Mx0wlJZIkaXxhWMM3/Uk/JUnSoFkpkSSpr8Y/q6YXTEokSeqxKe3o2gmHbyRJ0kywUiJJUk850VWSJKkDVkokSeox55RIkiRNmJUSSZJ6bECFEpMSSZL6KgxryGNIr0WSJPWYlRJJkvoqkAGN31gpkSRJM8FKiSRJPTacOolJiSRJvRXcp0SSJGniOk1Kkuyd5Mwklye5LMnju+xPkqSVJh3cpqXr4Zu/Av6pqp6VZCdgt477kyRJPdVZUpJkL+CJwKkAVXUXcFdX/UmStBINaEpJp5WSHwRuBP4+yaOBi4GXVtV3OuxTkqQVJO5TMqYdgKOAv6mqxwDfAV4596Ik65JsSLLh5m9u7jAcSZI0y7pMSjYBm6rqwvb+mTRJyn1U1fqqWltVa/fZd02H4UiSNCxbz76Z9G1aOuu7qr4OXJvkUe1DxwKXdtWfJEnqt65X37wEeHe78uZq4Pkd9ydJ0ooypDklnSYlVfU5YG2XfUiSpGFwm3lJknpsOHUSkxJJkvorwxq+8ewbSZI0E6yUSJLUU1uXBA/FkF6LJEnqMSslkiT12JDmlJiUSJLUY8NJSRy+kSRJM8JKiSRJPTag0RsrJZIkaTZYKZEkqaeaJcHDKZWYlEiS1GMO30iSJE2YlRJJknorZEDDN1ZKJEnSTLBSIklSjw1pTslMJSW77LCKRzx0j2mHMUgHPHjXaYcwWA/Za+dphzC2O++6Z9ohLMvpp66ddghj2+fJr5l2CMty87+8btohjO07d26Zdghju6dqu/Y3tNU3Dt9IkqSZMFOVEkmStAwZ1vCNlRJJkjQTrJRIktRjVkokSZImzEqJJEk9NqTN00xKJEnqqQCrhpOTOHwjSZJmg5USSZJ6bEjDN1ZKJEnSTLBSIklSjw1pSbBJiSRJPebwjSRJ0oRZKZEkqadcEixJktQBKyWSJPVWBjWnxKREkqS+yrBW33Q2fJPkUUk+N3L7dpKXddWfJEnqt84qJVV1BXAkQJLVwHXA2V31J0nSSjSgQsl2m+h6LHBVVV2znfqTJEk9s73mlJwMnL6d+pIkaUVolgQPp1bSeaUkyU7AicD7F3h+XZINSTbcuPnGrsORJEkzansM35wAXFJV35jvyapaX1Vrq2rtfmv22w7hSJI0HOngNi3bY/jmFBy6kSSpG8MZvem2UpJkN+ApwAe67EeSJPVfp5WSqrod2LfLPiRJWsmGtKOrZ99IkqSZ4DbzkiT12IBWBJuUSJLUZwPKSRy+kSRJs8FKiSRJfTagUomVEkmSNBOslEiS1FPNDqzDKZWYlEiS1FcZ1uobh28kSdJMMCmRJKnHpnUgX5Ljk1yR5Mokr5zn+ZcnuTTJfyT5WJKHL9WmSYkkSVqWJKuB04ATgMOBU5IcPueyzwJrq+pHgDOB/7lUuyYlkiT12XRKJUcDV1bV1VV1F/Be4KTRC6rqX9sz8AAuAA5cqlGTEkmStFwHANeO3N9badFCAAAN90lEQVTUPraQFwAfXqpRV99IktRb6WpJ8JokG0bur6+q9ffp+P5qvoaSPAdYC/zkUp2alEiS1GMdLQneXFVrF3l+E3DQyP0DgevnXpTkOOD3gJ+squ8u1anDN5IkabkuAg5LcmiSnYCTgXNGL0jyGODvgBOr6oZxGrVSIklSTy1nCe8kVdWWJC8GzgNWA2+tqo1JXg9sqKpzgD8D9gDen6ac89WqOnGxdmcqKSmgat4hqZmTnm2h15f3tY/69LWw8479Ko7ee29/vm5v+thrpx3Csuzzoy+edghju/miN007hLGt7tHPgweqqs4Fzp3z2KtHPj5uuW3OVFIiSZKWaUB5kEmJJEk9NqQD+fpVy5UkSYNlpUSSpB4b0jQWKyWSJGkmWCmRJKnHBlQoMSmRJKm3prVRSUccvpEkSTPBSokkST3mkmBJkqQJs1IiSVJPBZcES5IkTZyVEkmSemxAhRKTEkmSem1AWYnDN5IkaSZYKZEkqcdcEixJkjRhnSYlSX4zycYkX0xyepJduuxPkqSVJpn8bVo6S0qSHAD8BrC2qo4AVgMnd9WfJEkrUTq4TUvXwzc7ALsm2QHYDbi+4/4kSVJPdZaUVNV1wJ8DXwW+Bnyrqj7SVX+SJK1IAyqVdDl8sw9wEnAosD+we5LnzHPduiQbkmzYvPnGrsKRJEkzrsvhm+OA/6yqG6vqbuADwBPmXlRV66tqbVWtXbNmvw7DkSRpWJrCxuT/m5Yu9yn5KvBjSXYD7gCOBTZ02J8kSSvLlFfLTFqXc0ouBM4ELgG+0Pa1vqv+JElSv3W6o2tVvQZ4TZd9SJK0kg2oUOKOrpIkaTZ49o0kSX02oFKJlRJJkjQTrJRIktRb013CO2kmJZIk9ZhLgiVJkibMSokkST017VN9J81KiSRJmglWSiRJ6rMBlUpMSiRJ6rEhrb5x+EaSJM0EKyWSJPWYS4IlSZImzEqJJEk9NqBCiUmJJEm9FYdvJEmSJm6mKiUBMqSUb4b4vgrgnntr2iEsyw6r+/N303fvvmfaISzLzRe9adohjG2fx7102iGM7buXXzuFXofz870/3/GSJGnQZqpSIkmSxteMMEw7ismxUiJJkmaClRJJknpsQIUSkxJJkvrM4RtJkqQJs1IiSVKPeUqwJEnShFkpkSSpz4ZTKDEpkSSpzwaUkzh8I0mSZoOVEkmSeiqeEixJkjR5VkokSeqxIS0JNimRJKnPhpOTOHwjSZJmg5USSZJ6bECFkm4rJUlemuSLSTYmeVmXfUmSpH7rrFKS5AjghcDRwF3APyX5UFV9uas+JUlaaVwSPJ4fBi6oqturagvwCeDnOuxPkiT1WJdJyReBJybZN8luwNOAgzrsT5KkFSad/DctnQ3fVNVlSf4U+ChwG/B5YMvc65KsA9YBHHTwwV2FI0nS4ASHb8ZWVW+pqqOq6onATcD95pNU1fqqWltVa/dbs1+X4UiSpBnW6ZLgJA+pqhuSHAw8E3h8l/1JkqT+6nqfkrOS7AvcDfx6Vd3ccX+SJKmnOk1KquonumxfkqSVbkhzStzRVZKkHhvSgXyefSNJkmaClRJJkvoqwxq+sVIiSZJmgpUSSZJ6KgzrlGCTEkmS+mxAWYnDN5IkaSZYKZEkqcdcEixJkjRhVkokSeoxlwRLkiRNmJUSSZJ6bECFEpMSSZJ6bUBZicM3kiRp2ZIcn+SKJFcmeeU8z++c5H3t8xcmOWSpNk1KJEnqsXTw35J9JquB04ATgMOBU5IcPueyFwA3V9UPAX8B/OlS7ZqUSJKk5ToauLKqrq6qu4D3AifNueYk4O3tx2cCxyaLrxUyKZEkqadCsyR40rcxHABcO3J/U/vYvNdU1RbgW8C+izU6UxNdL7nk4s277phrJtzsGmDzhNvsUp/i7VOs0K94+xQr9CvePsUK/Yq3T7FCN/E+fMLtLeqSSy4+b9cds6aDpndJsmHk/vqqWj9yf77UpebcH+ea+5ippKSq9pt0m0k2VNXaSbfblT7F26dYoV/x9ilW6Fe8fYoV+hVvn2KF/sU7n6o6fkpdbwIOGrl/IHD9AtdsSrID8CDgpsUadfhGkiQt10XAYUkOTbITcDJwzpxrzgH+a/vxs4B/qar+VEokSdLsq6otSV4MnAesBt5aVRuTvB7YUFXnAG8B3pnkSpoKyclLtbsSkpL1S18yU/oUb59ihX7F26dYoV/x9ilW6Fe8fYoV+hfvTKmqc4Fz5zz26pGP7wR+fjltZolKiiRJ0nbhnBJJkjQTBp2ULLUF7ixJ8tYkNyT54rRjWUqSg5L8a5LLkmxM8tJpx7SQJLsk+fckn29jfd20YxpHktVJPpvkg9OOZTFJvpLkC0k+N2f54ExKsneSM5Nc3n79Pn7aMc0nyaPa93Tr7dtJXjbtuBaT5Dfb77EvJjk9yS7TjmkhSV7axrlx1t/XlWawwzftFrhfAp5CsyzpIuCUqrp0qoEtIMkTgduAd1TVEdOOZzFJHgY8rKouSbIncDHwjFl8b9vdA3evqtuS7Ah8GnhpVV0w5dAWleTlwFpgr6p6+rTjWUiSrwBrq6oXe1MkeTvwqap6c7tiYLequmXacS2m/Vl2HfC4qpr0Pk4TkeQAmu+tw6vqjiRnAOdW1dumG9n9JTmCZvfRo4G7gH8CXlRVX55qYAKGXSkZZwvcmVFVn2SJ9duzoqq+VlWXtB/fClzG/XfymwnVuK29u2N7m+lMPMmBwM8Ab552LEOSZC/giTQrAqiqu2Y9IWkdC1w1qwnJiB2AXdv9KHbj/ntWzIofBi6oqtvbXUY/AfzclGNSa8hJyThb4OoBak99fAxw4XQjWVg7FPI54Abgo1U1s7G2/hL4HeDeaQcyhgI+kuTiJOumHcwSfhC4Efj7dmjszUl2n3ZQYzgZOH3aQSymqq4D/hz4KvA14FtV9ZHpRrWgLwJPTLJvkt2Ap3HfTcA0RUNOSpa9va2WJ8kewFnAy6rq29OOZyFVdU9VHUmz4+DRbfl2JiV5OnBDVV087VjGdExVHUVzUuivt8OQs2oH4Cjgb6rqMcB3gFmfa7YTcCLw/mnHspgk+9BUog8F9gd2T/Kc6UY1v6q6jOa02o/SDN18Htgy1aD0PUNOSsbZAlfbqJ2fcRbw7qr6wLTjGUdbqv84MK1tmcdxDHBiO1fjvcCTk7xruiEtrKqub/9/A3A2zbDprNoEbBqplJ1Jk6TMshOAS6rqG9MOZAnHAf9ZVTdW1d3AB4AnTDmmBVXVW6rqqKp6Is2wufNJZsSQk5JxtsDVNmgnj74FuKyq3jDteBaTZL8ke7cf70rzw/Py6Ua1sKp6VVUdWFWH0HzN/ktVzeRfnEl2byc60w6DPJWmND6TqurrwLVJHtU+dCwwc5Oz5ziFGR+6aX0V+LEku7U/H46lmWs2k5I8pP3/wcAz6cd7vCIMdkfXhbbAnXJYC0pyOvAkYE2STcBrquot041qQccAzwW+0M7VAPjddne/WfMw4O3tCoZVwBlVNdPLbHvkocDZze8gdgDeU1X/NN2QlvQS4N3tHypXA8+fcjwLauc7PAX4lWnHspSqujDJmcAlNEMhn2W2d0s9K8m+wN3Ar1fVzdMOSI3BLgmWJEn9MuThG0mS1CMmJZIkaSaYlEiSpJlgUiJJkmaCSYkkSZoJJiVSh5Lc057y+sUk72+XeW5rW0/aempwkhMXO/m6PQ3317ahj9cm+a1xH59zzduSPGsZfR3Sh1OxJW0/JiVSt+6oqiPbk5/vAn519Mk0lv19WFXnVNWfLHLJ3sCykxJJmiaTEmn7+RTwQ22F4LIk/5tms6mDkjw1yflJLmkrKnsAJDk+yeVJPk2z8yTt46cmeVP78UOTnJ3k8+3tCcCfAI9oqzR/1l7320kuSvIfSV430tbvJbkiyT8Dj2IJSV7YtvP5JGfNqf4cl+RTSb7UnuOz9UDEPxvpe+Y3A5M0HSYl0nbQHud+AvCF9qFHAe8YORju94Hj2sPtNgAvT7IL8H+AnwV+AviBBZp/I/CJqno0zVkuG2kOmruqrdL8dpKnAofRnE1zJPDYJE9M8lia7ewfQ5P0/OgYL+cDVfWjbX+XAS8Yee4Q4CeBnwH+tn0NL6A5NfZH2/ZfmOTQMfqRtMIMdpt5aUbsOrIV/6dozgzaH7imqi5oH/8x4HDgM+2W7TsB5wP/H80hZ18GaA/mWzdPH08GngfNicjAt9pTW0c9tb19tr2/B02SsidwdlXd3vYxzvlQRyT5A5ohoj1ojnLY6oyquhf4cpKr29fwVOBHRuabPKjt+0tj9CVpBTEpkbp1R1UdOfpAm3h8Z/Qh4KNVdcqc644EJnUORIA/rqq/m9PHy7ahj7cBz6iqzyc5lebMpq3mtlVt3y+pqtHkhSSHLLNfSQPn8I00fRcAxyT5IWgOYkvySJrTjA9N8oj2ulMW+PyPAS9qP3d1kr2AW2mqIFudB/zSyFyVA9qTUj8J/FySXdsTf392jHj3BL6WZEfgv8x57ueTrGpj/kHgirbvF7XXk+SR7anCknQfVkqkKauqG9uKw+lJdm4f/v2q+lKSdcCHkmwGPg0cMU8TLwXWJ3kBcA/woqo6P8ln2iW3H27nlfwwcH5bqbkNeE5VXZLkfcDngGtohpiW8t+BC9vrv8B9k58rgE/QnCD8q1V1Z5I308w1uSRN5zcCzxjv3ZG0knhKsCRJmgkO30iSpJlgUiJJkmaCSYkkSZoJJiWSJGkmmJRIkqSZYFIiSZJmgkmJJEmaCSYlkiRpJvw/k48hrM60rXcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(norm_confusion_SVM, interpolation='nearest', cmap='Blues')\n",
    "plt.title(\"Normalized Confusion Matrix SVM\")\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(10))\n",
    "plt.yticks(range(10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T21:02:45.236342Z",
     "start_time": "2018-12-16T21:02:44.168117Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(norm_confusion_LR, interpolation='nearest', cmap='Blues')\n",
    "plt.title(\"Normalized Confusion Matrix SVM\")\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(10))\n",
    "plt.yticks(range(10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 12\n",
    "Have a look at the confusion matrices and comment on the obtained accuracies. Why some classes have lower accuracies and others an higher one ? Make some guesses on the possible causes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** From the plot above it is easy to notice that labels 2,4 and 6 have lower accuracies and they are more prone to missclassification. In fact, they represent the items pullover, coat and shirt, that look very similar to one another, whereas the highest accuracies are achieved for classes such as bag or ankle boot. Finally, from the comparison of the two confusion matrix, we can notice again that LR is worse than SVM with rbf kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "220.545px",
    "left": "1045.82px",
    "right": "20px",
    "top": "120px",
    "width": "330.545px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
